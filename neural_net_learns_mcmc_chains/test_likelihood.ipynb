{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9fa9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb77606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ffe84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Om\t\t\t\\Omega_m\n",
    "# Obh2\t\t\t\\Omega_{b}h^2\n",
    "# h\t\n",
    "datafile = 'chains/LCDM_phy_HD_nested_dynesty_multi_1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a57406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LoadDataSet(torch.utils.data.Dataset):\n",
    "class LoadDataSet:\n",
    "    '''\n",
    "    Prepare the dataset for regression\n",
    "    '''\n",
    "    def __init__(self, X, y, scale_data=False):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            # Apply scaling if necessary\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X)\n",
    "            self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a7249be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    Multilayer Perceptron for regression.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ncols = 3\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Linear(ncols, 200),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(200, 200),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(200, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "          Forward pass\n",
    "        '''\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df936f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1036, 3) (1036, 1)\n",
      "(400, 3) (100, 3)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(42)\n",
    "  \n",
    "    # Load Boston dataset\n",
    "    X = np.loadtxt(datafile, usecols=(2,3,4))\n",
    "    y = np.loadtxt(datafile, usecols=1).reshape(-1, 1)\n",
    "    randomize = np.random.permutation(len(X))\n",
    "    X = X[randomize]\n",
    "    y = y[randomize]\n",
    "    print(np.shape(X), np.shape(y))\n",
    "    X_test, y_test = X[:100, :], y[:100, :]\n",
    "    X, y = X[100:600, :], y[100:600, :]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "    print(np.shape(X_train), np.shape(X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90a6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = LoadDataSet(X_train, y_train)\n",
    "dataset_val = LoadDataSet(X_val, y_val)\n",
    "# dataset_test = LoadDataSet(X_test, y_test)\n",
    "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087b0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=1, shuffle=True, num_workers=1)\n",
    "validloader = torch.utils.data.DataLoader(dataset_val, batch_size=1, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516a419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MLP\n",
    "mlp = MLP()\n",
    "mlp.float()\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31e1668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MLP                                      --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       800\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       40,200\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─Linear: 2-5                       201\n",
       "=================================================================\n",
       "Total params: 41,201\n",
       "Trainable params: 41,201\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mlp, batch_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "572a5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 12.547\n",
      "Loss after mini-batch    11: 7.898\n",
      "Loss after mini-batch    21: 7.542\n",
      "Loss after mini-batch    31: 7.439\n",
      "Loss after mini-batch    41: 6.725\n",
      "Loss after mini-batch    51: 6.954\n",
      "Loss after mini-batch    61: 8.189\n",
      "Loss after mini-batch    71: 6.608\n",
      "Loss after mini-batch    81: 6.806\n",
      "Loss after mini-batch    91: 23.594\n",
      "Loss after mini-batch   101: 5.974\n",
      "Loss after mini-batch   111: 5.997\n",
      "Loss after mini-batch   121: 5.670\n",
      "Loss after mini-batch   131: 24.940\n",
      "Loss after mini-batch   141: 25.132\n",
      "Loss after mini-batch   151: 4.949\n",
      "Loss after mini-batch   161: 4.869\n",
      "Loss after mini-batch   171: 4.442\n",
      "Loss after mini-batch   181: 4.440\n",
      "Loss after mini-batch   191: 4.982\n",
      "Loss after mini-batch   201: 33.725\n",
      "Loss after mini-batch   211: 34.964\n",
      "Loss after mini-batch   221: 3.519\n",
      "Loss after mini-batch   231: 5.532\n",
      "Loss after mini-batch   241: 2.042\n",
      "Loss after mini-batch   251: 1.506\n",
      "Loss after mini-batch   261: 58.105\n",
      "Loss after mini-batch   271: 10.908\n",
      "Loss after mini-batch   281: 0.164\n",
      "Loss after mini-batch   291: 2.041\n",
      "Loss after mini-batch   301: 0.621\n",
      "Loss after mini-batch   311: 1.574\n",
      "Loss after mini-batch   321: 11.731\n",
      "Loss after mini-batch   331: 22.769\n",
      "Loss after mini-batch   341: 57.656\n",
      "Loss after mini-batch   351: 1.653\n",
      "Loss after mini-batch   361: 0.491\n",
      "Loss after mini-batch   371: 0.606\n",
      "Loss after mini-batch   381: 0.537\n",
      "Loss after mini-batch   391: 3.903\n",
      "Training Loss: 0.144 \t\t Validation Loss:0.730\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.600\n",
      "Loss after mini-batch    11: 7.601\n",
      "Loss after mini-batch    21: 0.667\n",
      "Loss after mini-batch    31: 0.506\n",
      "Loss after mini-batch    41: 3.704\n",
      "Loss after mini-batch    51: 0.227\n",
      "Loss after mini-batch    61: 1.005\n",
      "Loss after mini-batch    71: 0.100\n",
      "Loss after mini-batch    81: 3.984\n",
      "Loss after mini-batch    91: 3.817\n",
      "Loss after mini-batch   101: 0.005\n",
      "Loss after mini-batch   111: 24.392\n",
      "Loss after mini-batch   121: 0.097\n",
      "Loss after mini-batch   131: 0.395\n",
      "Loss after mini-batch   141: 0.429\n",
      "Loss after mini-batch   151: 0.238\n",
      "Loss after mini-batch   161: 2.068\n",
      "Loss after mini-batch   171: 0.329\n",
      "Loss after mini-batch   181: 1.920\n",
      "Loss after mini-batch   191: 5.807\n",
      "Loss after mini-batch   201: 0.160\n",
      "Loss after mini-batch   211: 28.313\n",
      "Loss after mini-batch   221: 0.481\n",
      "Loss after mini-batch   231: 0.642\n",
      "Loss after mini-batch   241: 10.774\n",
      "Loss after mini-batch   251: 35.294\n",
      "Loss after mini-batch   261: 16.463\n",
      "Loss after mini-batch   271: 2.204\n",
      "Loss after mini-batch   281: 6.009\n",
      "Loss after mini-batch   291: 0.004\n",
      "Loss after mini-batch   301: 0.969\n",
      "Loss after mini-batch   311: 1.927\n",
      "Loss after mini-batch   321: 10.649\n",
      "Loss after mini-batch   331: 0.479\n",
      "Loss after mini-batch   341: 12.641\n",
      "Loss after mini-batch   351: 0.550\n",
      "Loss after mini-batch   361: 1.123\n",
      "Loss after mini-batch   371: 0.448\n",
      "Loss after mini-batch   381: 0.379\n",
      "Loss after mini-batch   391: 6.247\n",
      "Training Loss: 0.502 \t\t Validation Loss:3.797\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 9.059\n",
      "Loss after mini-batch    11: 1.214\n",
      "Loss after mini-batch    21: 0.363\n",
      "Loss after mini-batch    31: 63.484\n",
      "Loss after mini-batch    41: 1.165\n",
      "Loss after mini-batch    51: 5.710\n",
      "Loss after mini-batch    61: 0.763\n",
      "Loss after mini-batch    71: 1.052\n",
      "Loss after mini-batch    81: 9.315\n",
      "Loss after mini-batch    91: 55.865\n",
      "Loss after mini-batch   101: 0.653\n",
      "Loss after mini-batch   111: 1.223\n",
      "Loss after mini-batch   121: 13.329\n",
      "Loss after mini-batch   131: 0.476\n",
      "Loss after mini-batch   141: 2.162\n",
      "Loss after mini-batch   151: 11.854\n",
      "Loss after mini-batch   161: 12.812\n",
      "Loss after mini-batch   171: 1.059\n",
      "Loss after mini-batch   181: 0.848\n",
      "Loss after mini-batch   191: 0.742\n",
      "Loss after mini-batch   201: 0.199\n",
      "Loss after mini-batch   211: 0.182\n",
      "Loss after mini-batch   221: 0.590\n",
      "Loss after mini-batch   231: 0.498\n",
      "Loss after mini-batch   241: 1.596\n",
      "Loss after mini-batch   251: 15.614\n",
      "Loss after mini-batch   261: 10.987\n",
      "Loss after mini-batch   271: 0.709\n",
      "Loss after mini-batch   281: 1.864\n",
      "Loss after mini-batch   291: 0.770\n",
      "Loss after mini-batch   301: 0.748\n",
      "Loss after mini-batch   311: 0.749\n",
      "Loss after mini-batch   321: 10.517\n",
      "Loss after mini-batch   331: 0.408\n",
      "Loss after mini-batch   341: 0.456\n",
      "Loss after mini-batch   351: 0.713\n",
      "Loss after mini-batch   361: 7.136\n",
      "Loss after mini-batch   371: 2.096\n",
      "Loss after mini-batch   381: 0.011\n",
      "Loss after mini-batch   391: 4.538\n",
      "Training Loss: 0.031 \t\t Validation Loss:0.436\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 4.857\n",
      "Loss after mini-batch    11: 2.156\n",
      "Loss after mini-batch    21: 55.957\n",
      "Loss after mini-batch    31: 0.644\n",
      "Loss after mini-batch    41: 0.901\n",
      "Loss after mini-batch    51: 34.160\n",
      "Loss after mini-batch    61: 0.802\n",
      "Loss after mini-batch    71: 2.178\n",
      "Loss after mini-batch    81: 2.330\n",
      "Loss after mini-batch    91: 0.928\n",
      "Loss after mini-batch   101: 3.635\n",
      "Loss after mini-batch   111: 0.587\n",
      "Loss after mini-batch   121: 18.927\n",
      "Loss after mini-batch   131: 13.808\n",
      "Loss after mini-batch   141: 0.614\n",
      "Loss after mini-batch   151: 4.534\n",
      "Loss after mini-batch   161: 0.489\n",
      "Loss after mini-batch   171: 0.498\n",
      "Loss after mini-batch   181: 5.296\n",
      "Loss after mini-batch   191: 0.273\n",
      "Loss after mini-batch   201: 0.356\n",
      "Loss after mini-batch   211: 1.844\n",
      "Loss after mini-batch   221: 0.614\n",
      "Loss after mini-batch   231: 0.594\n",
      "Loss after mini-batch   241: 0.415\n",
      "Loss after mini-batch   251: 0.454\n",
      "Loss after mini-batch   261: 4.559\n",
      "Loss after mini-batch   271: 0.512\n",
      "Loss after mini-batch   281: 0.480\n",
      "Loss after mini-batch   291: 0.005\n",
      "Loss after mini-batch   301: 1.098\n",
      "Loss after mini-batch   311: 0.542\n",
      "Loss after mini-batch   321: 4.725\n",
      "Loss after mini-batch   331: 6.006\n",
      "Loss after mini-batch   341: 0.042\n",
      "Loss after mini-batch   351: 0.042\n",
      "Loss after mini-batch   361: 0.927\n",
      "Loss after mini-batch   371: 1.054\n",
      "Loss after mini-batch   381: 1.106\n",
      "Loss after mini-batch   391: 2.095\n",
      "Training Loss: 0.859 \t\t Validation Loss:19.147\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.751\n",
      "Loss after mini-batch    11: 13.207\n",
      "Loss after mini-batch    21: 0.707\n",
      "Loss after mini-batch    31: 12.839\n",
      "Loss after mini-batch    41: 0.646\n",
      "Loss after mini-batch    51: 6.193\n",
      "Loss after mini-batch    61: 0.410\n",
      "Loss after mini-batch    71: 1.206\n",
      "Loss after mini-batch    81: 0.652\n",
      "Loss after mini-batch    91: 0.909\n",
      "Loss after mini-batch   101: 13.623\n",
      "Loss after mini-batch   111: 7.208\n",
      "Loss after mini-batch   121: 0.982\n",
      "Loss after mini-batch   131: 0.798\n",
      "Loss after mini-batch   141: 0.780\n",
      "Loss after mini-batch   151: 23.823\n",
      "Loss after mini-batch   161: 0.705\n",
      "Loss after mini-batch   171: 0.659\n",
      "Loss after mini-batch   181: 0.541\n",
      "Loss after mini-batch   191: 5.964\n",
      "Loss after mini-batch   201: 0.000\n",
      "Loss after mini-batch   211: 0.515\n",
      "Loss after mini-batch   221: 1.642\n",
      "Loss after mini-batch   231: 0.065\n",
      "Loss after mini-batch   241: 1.126\n",
      "Loss after mini-batch   251: 0.670\n",
      "Loss after mini-batch   261: 18.522\n",
      "Loss after mini-batch   271: 0.448\n",
      "Loss after mini-batch   281: 7.440\n",
      "Loss after mini-batch   291: 0.233\n",
      "Loss after mini-batch   301: 0.622\n",
      "Loss after mini-batch   311: 0.167\n",
      "Loss after mini-batch   321: 0.219\n",
      "Loss after mini-batch   331: 0.421\n",
      "Loss after mini-batch   341: 0.751\n",
      "Loss after mini-batch   351: 0.331\n",
      "Loss after mini-batch   361: 3.700\n",
      "Loss after mini-batch   371: 0.611\n",
      "Loss after mini-batch   381: 10.598\n",
      "Loss after mini-batch   391: 0.769\n",
      "Training Loss: 0.456 \t\t Validation Loss:1.178\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 4.071\n",
      "Loss after mini-batch    11: 0.347\n",
      "Loss after mini-batch    21: 34.825\n",
      "Loss after mini-batch    31: 0.659\n",
      "Loss after mini-batch    41: 9.090\n",
      "Loss after mini-batch    51: 2.835\n",
      "Loss after mini-batch    61: 85.333\n",
      "Loss after mini-batch    71: 0.583\n",
      "Loss after mini-batch    81: 0.031\n",
      "Loss after mini-batch    91: 0.068\n",
      "Loss after mini-batch   101: 28.634\n",
      "Loss after mini-batch   111: 7.225\n",
      "Loss after mini-batch   121: 3.601\n",
      "Loss after mini-batch   131: 0.924\n",
      "Loss after mini-batch   141: 0.445\n",
      "Loss after mini-batch   151: 0.525\n",
      "Loss after mini-batch   161: 0.421\n",
      "Loss after mini-batch   171: 0.605\n",
      "Loss after mini-batch   181: 0.113\n",
      "Loss after mini-batch   191: 9.786\n",
      "Loss after mini-batch   201: 0.755\n",
      "Loss after mini-batch   211: 10.801\n",
      "Loss after mini-batch   221: 5.667\n",
      "Loss after mini-batch   231: 0.751\n",
      "Loss after mini-batch   241: 1.595\n",
      "Loss after mini-batch   251: 11.608\n",
      "Loss after mini-batch   261: 0.372\n",
      "Loss after mini-batch   271: 2.501\n",
      "Loss after mini-batch   281: 1.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   291: 0.457\n",
      "Loss after mini-batch   301: 9.442\n",
      "Loss after mini-batch   311: 18.675\n",
      "Loss after mini-batch   321: 0.871\n",
      "Loss after mini-batch   331: 3.607\n",
      "Loss after mini-batch   341: 22.576\n",
      "Loss after mini-batch   351: 0.882\n",
      "Loss after mini-batch   361: 0.967\n",
      "Loss after mini-batch   371: 17.589\n",
      "Loss after mini-batch   381: 0.239\n",
      "Loss after mini-batch   391: 0.634\n",
      "Training Loss: 5.654 \t\t Validation Loss:6.643\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.884\n",
      "Loss after mini-batch    11: 17.366\n",
      "Loss after mini-batch    21: 0.796\n",
      "Loss after mini-batch    31: 0.703\n",
      "Loss after mini-batch    41: 0.624\n",
      "Loss after mini-batch    51: 0.697\n",
      "Loss after mini-batch    61: 4.147\n",
      "Loss after mini-batch    71: 0.471\n",
      "Loss after mini-batch    81: 0.898\n",
      "Loss after mini-batch    91: 0.373\n",
      "Loss after mini-batch   101: 16.401\n",
      "Loss after mini-batch   111: 1.573\n",
      "Loss after mini-batch   121: 56.095\n",
      "Loss after mini-batch   131: 5.845\n",
      "Loss after mini-batch   141: 0.937\n",
      "Loss after mini-batch   151: 13.883\n",
      "Loss after mini-batch   161: 0.676\n",
      "Loss after mini-batch   171: 0.758\n",
      "Loss after mini-batch   181: 0.955\n",
      "Loss after mini-batch   191: 0.271\n",
      "Loss after mini-batch   201: 5.091\n",
      "Loss after mini-batch   211: 0.490\n",
      "Loss after mini-batch   221: 0.800\n",
      "Loss after mini-batch   231: 0.557\n",
      "Loss after mini-batch   241: 2.297\n",
      "Loss after mini-batch   251: 34.027\n",
      "Loss after mini-batch   261: 0.706\n",
      "Loss after mini-batch   271: 0.716\n",
      "Loss after mini-batch   281: 0.814\n",
      "Loss after mini-batch   291: 0.708\n",
      "Loss after mini-batch   301: 0.738\n",
      "Loss after mini-batch   311: 0.798\n",
      "Loss after mini-batch   321: 0.355\n",
      "Loss after mini-batch   331: 0.738\n",
      "Loss after mini-batch   341: 0.442\n",
      "Loss after mini-batch   351: 0.650\n",
      "Loss after mini-batch   361: 1.171\n",
      "Loss after mini-batch   371: 0.307\n",
      "Loss after mini-batch   381: 0.108\n",
      "Loss after mini-batch   391: 0.651\n",
      "Training Loss: 0.534 \t\t Validation Loss:3.765\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 22.802\n",
      "Loss after mini-batch    11: 0.460\n",
      "Loss after mini-batch    21: 13.035\n",
      "Loss after mini-batch    31: 0.418\n",
      "Loss after mini-batch    41: 10.688\n",
      "Loss after mini-batch    51: 11.982\n",
      "Loss after mini-batch    61: 1.961\n",
      "Loss after mini-batch    71: 0.418\n",
      "Loss after mini-batch    81: 0.450\n",
      "Loss after mini-batch    91: 0.036\n",
      "Loss after mini-batch   101: 0.167\n",
      "Loss after mini-batch   111: 0.370\n",
      "Loss after mini-batch   121: 0.304\n",
      "Loss after mini-batch   131: 1.891\n",
      "Loss after mini-batch   141: 0.291\n",
      "Loss after mini-batch   151: 13.216\n",
      "Loss after mini-batch   161: 0.512\n",
      "Loss after mini-batch   171: 2.046\n",
      "Loss after mini-batch   181: 0.808\n",
      "Loss after mini-batch   191: 0.333\n",
      "Loss after mini-batch   201: 0.672\n",
      "Loss after mini-batch   211: 0.337\n",
      "Loss after mini-batch   221: 0.237\n",
      "Loss after mini-batch   231: 0.514\n",
      "Loss after mini-batch   241: 0.249\n",
      "Loss after mini-batch   251: 1.676\n",
      "Loss after mini-batch   261: 0.155\n",
      "Loss after mini-batch   271: 0.873\n",
      "Loss after mini-batch   281: 7.468\n",
      "Loss after mini-batch   291: 9.487\n",
      "Loss after mini-batch   301: 16.403\n",
      "Loss after mini-batch   311: 0.737\n",
      "Loss after mini-batch   321: 2.428\n",
      "Loss after mini-batch   331: 28.755\n",
      "Loss after mini-batch   341: 2.375\n",
      "Loss after mini-batch   351: 0.743\n",
      "Loss after mini-batch   361: 1.052\n",
      "Loss after mini-batch   371: 23.240\n",
      "Loss after mini-batch   381: 1.046\n",
      "Loss after mini-batch   391: 0.535\n",
      "Training Loss: 1.164 \t\t Validation Loss:2.343\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 1.145\n",
      "Loss after mini-batch    11: 2.654\n",
      "Loss after mini-batch    21: 3.407\n",
      "Loss after mini-batch    31: 1.017\n",
      "Loss after mini-batch    41: 30.905\n",
      "Loss after mini-batch    51: 0.967\n",
      "Loss after mini-batch    61: 0.546\n",
      "Loss after mini-batch    71: 1.177\n",
      "Loss after mini-batch    81: 0.808\n",
      "Loss after mini-batch    91: 4.205\n",
      "Loss after mini-batch   101: 0.432\n",
      "Loss after mini-batch   111: 0.915\n",
      "Loss after mini-batch   121: 0.804\n",
      "Loss after mini-batch   131: 7.020\n",
      "Loss after mini-batch   141: 0.516\n",
      "Loss after mini-batch   151: 0.158\n",
      "Loss after mini-batch   161: 0.509\n",
      "Loss after mini-batch   171: 5.841\n",
      "Loss after mini-batch   181: 0.309\n",
      "Loss after mini-batch   191: 0.808\n",
      "Loss after mini-batch   201: 12.703\n",
      "Loss after mini-batch   211: 0.755\n",
      "Loss after mini-batch   221: 4.121\n",
      "Loss after mini-batch   231: 12.896\n",
      "Loss after mini-batch   241: 0.881\n",
      "Loss after mini-batch   251: 5.867\n",
      "Loss after mini-batch   261: 0.802\n",
      "Loss after mini-batch   271: 0.081\n",
      "Loss after mini-batch   281: 0.788\n",
      "Loss after mini-batch   291: 1.498\n",
      "Loss after mini-batch   301: 0.777\n",
      "Loss after mini-batch   311: 3.014\n",
      "Loss after mini-batch   321: 2.480\n",
      "Loss after mini-batch   331: 9.066\n",
      "Loss after mini-batch   341: 0.928\n",
      "Loss after mini-batch   351: 0.372\n",
      "Loss after mini-batch   361: 1.134\n",
      "Loss after mini-batch   371: 1.963\n",
      "Loss after mini-batch   381: 0.007\n",
      "Loss after mini-batch   391: 0.834\n",
      "Training Loss: 11.944 \t\t Validation Loss:12.554\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.627\n",
      "Loss after mini-batch    11: 7.301\n",
      "Loss after mini-batch    21: 8.183\n",
      "Loss after mini-batch    31: 4.373\n",
      "Loss after mini-batch    41: 27.002\n",
      "Loss after mini-batch    51: 0.202\n",
      "Loss after mini-batch    61: 0.547\n",
      "Loss after mini-batch    71: 0.726\n",
      "Loss after mini-batch    81: 0.404\n",
      "Loss after mini-batch    91: 0.241\n",
      "Loss after mini-batch   101: 3.175\n",
      "Loss after mini-batch   111: 0.405\n",
      "Loss after mini-batch   121: 3.428\n",
      "Loss after mini-batch   131: 22.733\n",
      "Loss after mini-batch   141: 12.765\n",
      "Loss after mini-batch   151: 0.599\n",
      "Loss after mini-batch   161: 0.640\n",
      "Loss after mini-batch   171: 17.097\n",
      "Loss after mini-batch   181: 0.611\n",
      "Loss after mini-batch   191: 2.232\n",
      "Loss after mini-batch   201: 0.208\n",
      "Loss after mini-batch   211: 0.873\n",
      "Loss after mini-batch   221: 0.338\n",
      "Loss after mini-batch   231: 5.606\n",
      "Loss after mini-batch   241: 0.225\n",
      "Loss after mini-batch   251: 0.650\n",
      "Loss after mini-batch   261: 0.891\n",
      "Loss after mini-batch   271: 0.761\n",
      "Loss after mini-batch   281: 0.572\n",
      "Loss after mini-batch   291: 0.010\n",
      "Loss after mini-batch   301: 0.605\n",
      "Loss after mini-batch   311: 0.030\n",
      "Loss after mini-batch   321: 0.423\n",
      "Loss after mini-batch   331: 4.945\n",
      "Loss after mini-batch   341: 0.529\n",
      "Loss after mini-batch   351: 5.904\n",
      "Loss after mini-batch   361: 2.074\n",
      "Loss after mini-batch   371: 0.647\n",
      "Loss after mini-batch   381: 0.118\n",
      "Loss after mini-batch   391: 0.665\n",
      "Training Loss: 0.769 \t\t Validation Loss:1.493\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.024\n",
      "Loss after mini-batch    11: 9.879\n",
      "Loss after mini-batch    21: 0.905\n",
      "Loss after mini-batch    31: 5.728\n",
      "Loss after mini-batch    41: 1.222\n",
      "Loss after mini-batch    51: 0.766\n",
      "Loss after mini-batch    61: 1.542\n",
      "Loss after mini-batch    71: 0.706\n",
      "Loss after mini-batch    81: 9.258\n",
      "Loss after mini-batch    91: 0.291\n",
      "Loss after mini-batch   101: 9.276\n",
      "Loss after mini-batch   111: 0.527\n",
      "Loss after mini-batch   121: 0.232\n",
      "Loss after mini-batch   131: 0.043\n",
      "Loss after mini-batch   141: 10.823\n",
      "Loss after mini-batch   151: 5.355\n",
      "Loss after mini-batch   161: 0.080\n",
      "Loss after mini-batch   171: 10.260\n",
      "Loss after mini-batch   181: 2.628\n",
      "Loss after mini-batch   191: 9.097\n",
      "Loss after mini-batch   201: 0.597\n",
      "Loss after mini-batch   211: 0.668\n",
      "Loss after mini-batch   221: 5.139\n",
      "Loss after mini-batch   231: 0.300\n",
      "Loss after mini-batch   241: 0.461\n",
      "Loss after mini-batch   251: 0.469\n",
      "Loss after mini-batch   261: 0.374\n",
      "Loss after mini-batch   271: 0.440\n",
      "Loss after mini-batch   281: 0.268\n",
      "Loss after mini-batch   291: 6.729\n",
      "Loss after mini-batch   301: 15.407\n",
      "Loss after mini-batch   311: 0.507\n",
      "Loss after mini-batch   321: 0.460\n",
      "Loss after mini-batch   331: 4.103\n",
      "Loss after mini-batch   341: 0.504\n",
      "Loss after mini-batch   351: 6.322\n",
      "Loss after mini-batch   361: 14.316\n",
      "Loss after mini-batch   371: 2.823\n",
      "Loss after mini-batch   381: 30.848\n",
      "Loss after mini-batch   391: 1.008\n",
      "Training Loss: 1.321 \t\t Validation Loss:1.882\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.919\n",
      "Loss after mini-batch    11: 0.089\n",
      "Loss after mini-batch    21: 63.332\n",
      "Loss after mini-batch    31: 11.592\n",
      "Loss after mini-batch    41: 0.986\n",
      "Loss after mini-batch    51: 0.156\n",
      "Loss after mini-batch    61: 1.437\n",
      "Loss after mini-batch    71: 0.456\n",
      "Loss after mini-batch    81: 0.911\n",
      "Loss after mini-batch    91: 2.757\n",
      "Loss after mini-batch   101: 50.373\n",
      "Loss after mini-batch   111: 0.470\n",
      "Loss after mini-batch   121: 0.636\n",
      "Loss after mini-batch   131: 5.595\n",
      "Loss after mini-batch   141: 5.772\n",
      "Loss after mini-batch   151: 0.556\n",
      "Loss after mini-batch   161: 0.179\n",
      "Loss after mini-batch   171: 0.990\n",
      "Loss after mini-batch   181: 0.632\n",
      "Loss after mini-batch   191: 0.665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   201: 0.053\n",
      "Loss after mini-batch   211: 11.773\n",
      "Loss after mini-batch   221: 0.257\n",
      "Loss after mini-batch   231: 3.131\n",
      "Loss after mini-batch   241: 3.338\n",
      "Loss after mini-batch   251: 0.308\n",
      "Loss after mini-batch   261: 4.381\n",
      "Loss after mini-batch   271: 74.553\n",
      "Loss after mini-batch   281: 0.436\n",
      "Loss after mini-batch   291: 23.216\n",
      "Loss after mini-batch   301: 1.938\n",
      "Loss after mini-batch   311: 0.702\n",
      "Loss after mini-batch   321: 0.479\n",
      "Loss after mini-batch   331: 0.626\n",
      "Loss after mini-batch   341: 29.055\n",
      "Loss after mini-batch   351: 0.164\n",
      "Loss after mini-batch   361: 0.686\n",
      "Loss after mini-batch   371: 0.600\n",
      "Loss after mini-batch   381: 0.506\n",
      "Loss after mini-batch   391: 0.161\n",
      "Training Loss: 0.228 \t\t Validation Loss:4.405\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.110\n",
      "Loss after mini-batch    11: 0.397\n",
      "Loss after mini-batch    21: 0.335\n",
      "Loss after mini-batch    31: 0.380\n",
      "Loss after mini-batch    41: 5.049\n",
      "Loss after mini-batch    51: 0.316\n",
      "Loss after mini-batch    61: 0.216\n",
      "Loss after mini-batch    71: 0.414\n",
      "Loss after mini-batch    81: 0.442\n",
      "Loss after mini-batch    91: 0.893\n",
      "Loss after mini-batch   101: 17.684\n",
      "Loss after mini-batch   111: 0.478\n",
      "Loss after mini-batch   121: 0.433\n",
      "Loss after mini-batch   131: 5.355\n",
      "Loss after mini-batch   141: 0.570\n",
      "Loss after mini-batch   151: 0.494\n",
      "Loss after mini-batch   161: 0.054\n",
      "Loss after mini-batch   171: 1.308\n",
      "Loss after mini-batch   181: 13.581\n",
      "Loss after mini-batch   191: 0.546\n",
      "Loss after mini-batch   201: 45.886\n",
      "Loss after mini-batch   211: 0.905\n",
      "Loss after mini-batch   221: 0.719\n",
      "Loss after mini-batch   231: 0.729\n",
      "Loss after mini-batch   241: 0.762\n",
      "Loss after mini-batch   251: 0.778\n",
      "Loss after mini-batch   261: 0.557\n",
      "Loss after mini-batch   271: 1.022\n",
      "Loss after mini-batch   281: 13.190\n",
      "Loss after mini-batch   291: 15.120\n",
      "Loss after mini-batch   301: 2.164\n",
      "Loss after mini-batch   311: 12.696\n",
      "Loss after mini-batch   321: 0.700\n",
      "Loss after mini-batch   331: 0.067\n",
      "Loss after mini-batch   341: 0.541\n",
      "Loss after mini-batch   351: 2.262\n",
      "Loss after mini-batch   361: 0.665\n",
      "Loss after mini-batch   371: 74.896\n",
      "Loss after mini-batch   381: 16.096\n",
      "Loss after mini-batch   391: 3.617\n",
      "Training Loss: 7.856 \t\t Validation Loss:25.148\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 56.659\n",
      "Loss after mini-batch    11: 0.994\n",
      "Loss after mini-batch    21: 0.977\n",
      "Loss after mini-batch    31: 0.909\n",
      "Loss after mini-batch    41: 15.001\n",
      "Loss after mini-batch    51: 2.297\n",
      "Loss after mini-batch    61: 0.779\n",
      "Loss after mini-batch    71: 0.657\n",
      "Loss after mini-batch    81: 27.530\n",
      "Loss after mini-batch    91: 0.492\n",
      "Loss after mini-batch   101: 28.993\n",
      "Loss after mini-batch   111: 0.356\n",
      "Loss after mini-batch   121: 0.210\n",
      "Loss after mini-batch   131: 0.140\n",
      "Loss after mini-batch   141: 23.741\n",
      "Loss after mini-batch   151: 0.590\n",
      "Loss after mini-batch   161: 2.197\n",
      "Loss after mini-batch   171: 0.070\n",
      "Loss after mini-batch   181: 11.910\n",
      "Loss after mini-batch   191: 0.357\n",
      "Loss after mini-batch   201: 4.010\n",
      "Loss after mini-batch   211: 0.581\n",
      "Loss after mini-batch   221: 0.527\n",
      "Loss after mini-batch   231: 11.409\n",
      "Loss after mini-batch   241: 17.405\n",
      "Loss after mini-batch   251: 0.720\n",
      "Loss after mini-batch   261: 0.640\n",
      "Loss after mini-batch   271: 0.562\n",
      "Loss after mini-batch   281: 0.685\n",
      "Loss after mini-batch   291: 0.940\n",
      "Loss after mini-batch   301: 16.081\n",
      "Loss after mini-batch   311: 8.080\n",
      "Loss after mini-batch   321: 3.252\n",
      "Loss after mini-batch   331: 5.610\n",
      "Loss after mini-batch   341: 0.700\n",
      "Loss after mini-batch   351: 0.833\n",
      "Loss after mini-batch   361: 13.700\n",
      "Loss after mini-batch   371: 1.031\n",
      "Loss after mini-batch   381: 6.437\n",
      "Loss after mini-batch   391: 3.343\n",
      "Training Loss: 22.151 \t\t Validation Loss:22.825\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 17.252\n",
      "Loss after mini-batch    11: 0.987\n",
      "Loss after mini-batch    21: 34.643\n",
      "Loss after mini-batch    31: 0.931\n",
      "Loss after mini-batch    41: 1.084\n",
      "Loss after mini-batch    51: 0.939\n",
      "Loss after mini-batch    61: 0.851\n",
      "Loss after mini-batch    71: 6.989\n",
      "Loss after mini-batch    81: 0.682\n",
      "Loss after mini-batch    91: 0.074\n",
      "Loss after mini-batch   101: 0.210\n",
      "Loss after mini-batch   111: 0.347\n",
      "Loss after mini-batch   121: 0.790\n",
      "Loss after mini-batch   131: 3.609\n",
      "Loss after mini-batch   141: 14.934\n",
      "Loss after mini-batch   151: 8.444\n",
      "Loss after mini-batch   161: 2.407\n",
      "Loss after mini-batch   171: 20.169\n",
      "Loss after mini-batch   181: 0.931\n",
      "Loss after mini-batch   191: 0.869\n",
      "Loss after mini-batch   201: 0.679\n",
      "Loss after mini-batch   211: 12.313\n",
      "Loss after mini-batch   221: 0.136\n",
      "Loss after mini-batch   231: 0.085\n",
      "Loss after mini-batch   241: 0.503\n",
      "Loss after mini-batch   251: 55.817\n",
      "Loss after mini-batch   261: 1.442\n",
      "Loss after mini-batch   271: 0.866\n",
      "Loss after mini-batch   281: 0.747\n",
      "Loss after mini-batch   291: 57.143\n",
      "Loss after mini-batch   301: 0.888\n",
      "Loss after mini-batch   311: 0.321\n",
      "Loss after mini-batch   321: 0.291\n",
      "Loss after mini-batch   331: 0.700\n",
      "Loss after mini-batch   341: 0.743\n",
      "Loss after mini-batch   351: 0.013\n",
      "Loss after mini-batch   361: 16.113\n",
      "Loss after mini-batch   371: 28.141\n",
      "Loss after mini-batch   381: 0.342\n",
      "Loss after mini-batch   391: 0.552\n",
      "Training Loss: 0.565 \t\t Validation Loss:1.183\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.362\n",
      "Loss after mini-batch    11: 8.669\n",
      "Loss after mini-batch    21: 0.429\n",
      "Loss after mini-batch    31: 0.530\n",
      "Loss after mini-batch    41: 0.165\n",
      "Loss after mini-batch    51: 9.203\n",
      "Loss after mini-batch    61: 0.113\n",
      "Loss after mini-batch    71: 9.068\n",
      "Loss after mini-batch    81: 0.180\n",
      "Loss after mini-batch    91: 0.388\n",
      "Loss after mini-batch   101: 3.834\n",
      "Loss after mini-batch   111: 0.636\n",
      "Loss after mini-batch   121: 3.204\n",
      "Loss after mini-batch   131: 1.855\n",
      "Loss after mini-batch   141: 10.429\n",
      "Loss after mini-batch   151: 0.713\n",
      "Loss after mini-batch   161: 0.755\n",
      "Loss after mini-batch   171: 20.337\n",
      "Loss after mini-batch   181: 8.071\n",
      "Loss after mini-batch   191: 0.297\n",
      "Loss after mini-batch   201: 0.333\n",
      "Loss after mini-batch   211: 0.814\n",
      "Loss after mini-batch   221: 12.210\n",
      "Loss after mini-batch   231: 0.655\n",
      "Loss after mini-batch   241: 0.319\n",
      "Loss after mini-batch   251: 5.790\n",
      "Loss after mini-batch   261: 0.565\n",
      "Loss after mini-batch   271: 3.395\n",
      "Loss after mini-batch   281: 1.770\n",
      "Loss after mini-batch   291: 11.701\n",
      "Loss after mini-batch   301: 16.942\n",
      "Loss after mini-batch   311: 0.351\n",
      "Loss after mini-batch   321: 0.347\n",
      "Loss after mini-batch   331: 0.858\n",
      "Loss after mini-batch   341: 0.256\n",
      "Loss after mini-batch   351: 1.080\n",
      "Loss after mini-batch   361: 0.119\n",
      "Loss after mini-batch   371: 1.992\n",
      "Loss after mini-batch   381: 13.728\n",
      "Loss after mini-batch   391: 8.282\n",
      "Training Loss: 0.999 \t\t Validation Loss:2.025\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 3.352\n",
      "Loss after mini-batch    11: 0.257\n",
      "Loss after mini-batch    21: 5.502\n",
      "Loss after mini-batch    31: 11.253\n",
      "Loss after mini-batch    41: 0.716\n",
      "Loss after mini-batch    51: 0.934\n",
      "Loss after mini-batch    61: 14.784\n",
      "Loss after mini-batch    71: 17.086\n",
      "Loss after mini-batch    81: 0.693\n",
      "Loss after mini-batch    91: 0.646\n",
      "Loss after mini-batch   101: 0.174\n",
      "Loss after mini-batch   111: 0.257\n",
      "Loss after mini-batch   121: 1.645\n",
      "Loss after mini-batch   131: 0.747\n",
      "Loss after mini-batch   141: 0.888\n",
      "Loss after mini-batch   151: 0.864\n",
      "Loss after mini-batch   161: 0.034\n",
      "Loss after mini-batch   171: 0.080\n",
      "Loss after mini-batch   181: 12.886\n",
      "Loss after mini-batch   191: 34.844\n",
      "Loss after mini-batch   201: 0.181\n",
      "Loss after mini-batch   211: 3.382\n",
      "Loss after mini-batch   221: 0.889\n",
      "Loss after mini-batch   231: 1.159\n",
      "Loss after mini-batch   241: 0.955\n",
      "Loss after mini-batch   251: 5.570\n",
      "Loss after mini-batch   261: 0.590\n",
      "Loss after mini-batch   271: 26.216\n",
      "Loss after mini-batch   281: 8.527\n",
      "Loss after mini-batch   291: 1.080\n",
      "Loss after mini-batch   301: 11.758\n",
      "Loss after mini-batch   311: 0.937\n",
      "Loss after mini-batch   321: 4.638\n",
      "Loss after mini-batch   331: 3.025\n",
      "Loss after mini-batch   341: 0.986\n",
      "Loss after mini-batch   351: 0.774\n",
      "Loss after mini-batch   361: 0.184\n",
      "Loss after mini-batch   371: 57.148\n",
      "Loss after mini-batch   381: 0.031\n",
      "Loss after mini-batch   391: 0.454\n",
      "Training Loss: 0.569 \t\t Validation Loss:0.985\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.080\n",
      "Loss after mini-batch    11: 74.772\n",
      "Loss after mini-batch    21: 0.176\n",
      "Loss after mini-batch    31: 0.400\n",
      "Loss after mini-batch    41: 0.055\n",
      "Loss after mini-batch    51: 4.453\n",
      "Loss after mini-batch    61: 3.765\n",
      "Loss after mini-batch    71: 5.851\n",
      "Loss after mini-batch    81: 0.414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch    91: 0.798\n",
      "Loss after mini-batch   101: 2.085\n",
      "Loss after mini-batch   111: 0.883\n",
      "Loss after mini-batch   121: 26.347\n",
      "Loss after mini-batch   131: 0.660\n",
      "Loss after mini-batch   141: 0.624\n",
      "Loss after mini-batch   151: 0.561\n",
      "Loss after mini-batch   161: 1.521\n",
      "Loss after mini-batch   171: 0.492\n",
      "Loss after mini-batch   181: 0.493\n",
      "Loss after mini-batch   191: 0.485\n",
      "Loss after mini-batch   201: 16.292\n",
      "Loss after mini-batch   211: 0.517\n",
      "Loss after mini-batch   221: 23.249\n",
      "Loss after mini-batch   231: 0.232\n",
      "Loss after mini-batch   241: 11.525\n",
      "Loss after mini-batch   251: 0.049\n",
      "Loss after mini-batch   261: 0.865\n",
      "Loss after mini-batch   271: 0.795\n",
      "Loss after mini-batch   281: 0.187\n",
      "Loss after mini-batch   291: 0.900\n",
      "Loss after mini-batch   301: 0.933\n",
      "Loss after mini-batch   311: 0.855\n",
      "Loss after mini-batch   321: 14.798\n",
      "Loss after mini-batch   331: 7.196\n",
      "Loss after mini-batch   341: 0.738\n",
      "Loss after mini-batch   351: 0.617\n",
      "Loss after mini-batch   361: 0.181\n",
      "Loss after mini-batch   371: 0.407\n",
      "Loss after mini-batch   381: 0.429\n",
      "Loss after mini-batch   391: 1.618\n",
      "Training Loss: 0.272 \t\t Validation Loss:0.515\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.272\n",
      "Loss after mini-batch    11: 0.255\n",
      "Loss after mini-batch    21: 4.865\n",
      "Loss after mini-batch    31: 0.635\n",
      "Loss after mini-batch    41: 4.492\n",
      "Loss after mini-batch    51: 0.494\n",
      "Loss after mini-batch    61: 0.773\n",
      "Loss after mini-batch    71: 1.284\n",
      "Loss after mini-batch    81: 1.016\n",
      "Loss after mini-batch    91: 0.921\n",
      "Loss after mini-batch   101: 0.886\n",
      "Loss after mini-batch   111: 1.903\n",
      "Loss after mini-batch   121: 23.146\n",
      "Loss after mini-batch   131: 0.693\n",
      "Loss after mini-batch   141: 0.003\n",
      "Loss after mini-batch   151: 0.328\n",
      "Loss after mini-batch   161: 0.289\n",
      "Loss after mini-batch   171: 0.331\n",
      "Loss after mini-batch   181: 0.331\n",
      "Loss after mini-batch   191: 0.222\n",
      "Loss after mini-batch   201: 0.008\n",
      "Loss after mini-batch   211: 0.215\n",
      "Loss after mini-batch   221: 20.584\n",
      "Loss after mini-batch   231: 0.276\n",
      "Loss after mini-batch   241: 55.617\n",
      "Loss after mini-batch   251: 0.404\n",
      "Loss after mini-batch   261: 0.605\n",
      "Loss after mini-batch   271: 1.117\n",
      "Loss after mini-batch   281: 0.020\n",
      "Loss after mini-batch   291: 0.024\n",
      "Loss after mini-batch   301: 3.473\n",
      "Loss after mini-batch   311: 0.024\n",
      "Loss after mini-batch   321: 3.944\n",
      "Loss after mini-batch   331: 4.110\n",
      "Loss after mini-batch   341: 0.688\n",
      "Loss after mini-batch   351: 1.514\n",
      "Loss after mini-batch   361: 0.893\n",
      "Loss after mini-batch   371: 0.203\n",
      "Loss after mini-batch   381: 2.992\n",
      "Loss after mini-batch   391: 10.135\n",
      "Training Loss: 40.999 \t\t Validation Loss:41.361\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 7.230\n",
      "Loss after mini-batch    11: 32.926\n",
      "Loss after mini-batch    21: 0.974\n",
      "Loss after mini-batch    31: 1.015\n",
      "Loss after mini-batch    41: 11.678\n",
      "Loss after mini-batch    51: 0.941\n",
      "Loss after mini-batch    61: 74.106\n",
      "Loss after mini-batch    71: 0.950\n",
      "Loss after mini-batch    81: 26.346\n",
      "Loss after mini-batch    91: 0.666\n",
      "Loss after mini-batch   101: 0.278\n",
      "Loss after mini-batch   111: 1.112\n",
      "Loss after mini-batch   121: 2.806\n",
      "Loss after mini-batch   131: 0.334\n",
      "Loss after mini-batch   141: 3.723\n",
      "Loss after mini-batch   151: 0.415\n",
      "Loss after mini-batch   161: 9.088\n",
      "Loss after mini-batch   171: 0.217\n",
      "Loss after mini-batch   181: 1.830\n",
      "Loss after mini-batch   191: 9.622\n",
      "Loss after mini-batch   201: 2.304\n",
      "Loss after mini-batch   211: 1.419\n",
      "Loss after mini-batch   221: 0.155\n",
      "Loss after mini-batch   231: 16.962\n",
      "Loss after mini-batch   241: 0.129\n",
      "Loss after mini-batch   251: 0.409\n",
      "Loss after mini-batch   261: 0.374\n",
      "Loss after mini-batch   271: 0.547\n",
      "Loss after mini-batch   281: 11.223\n",
      "Loss after mini-batch   291: 0.537\n",
      "Loss after mini-batch   301: 0.816\n",
      "Loss after mini-batch   311: 0.637\n",
      "Loss after mini-batch   321: 1.699\n",
      "Loss after mini-batch   331: 2.435\n",
      "Loss after mini-batch   341: 0.069\n",
      "Loss after mini-batch   351: 30.552\n",
      "Loss after mini-batch   361: 2.339\n",
      "Loss after mini-batch   371: 2.113\n",
      "Loss after mini-batch   381: 20.059\n",
      "Loss after mini-batch   391: 0.708\n",
      "Training Loss: 0.260 \t\t Validation Loss:1.233\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 3.155\n",
      "Loss after mini-batch    11: 0.441\n",
      "Loss after mini-batch    21: 0.780\n",
      "Loss after mini-batch    31: 55.291\n",
      "Loss after mini-batch    41: 0.882\n",
      "Loss after mini-batch    51: 13.071\n",
      "Loss after mini-batch    61: 0.954\n",
      "Loss after mini-batch    71: 0.925\n",
      "Loss after mini-batch    81: 83.829\n",
      "Loss after mini-batch    91: 0.987\n",
      "Loss after mini-batch   101: 0.387\n",
      "Loss after mini-batch   111: 0.741\n",
      "Loss after mini-batch   121: 9.951\n",
      "Loss after mini-batch   131: 3.082\n",
      "Loss after mini-batch   141: 1.402\n",
      "Loss after mini-batch   151: 1.148\n",
      "Loss after mini-batch   161: 0.742\n",
      "Loss after mini-batch   171: 1.172\n",
      "Loss after mini-batch   181: 0.477\n",
      "Loss after mini-batch   191: 0.709\n",
      "Loss after mini-batch   201: 5.558\n",
      "Loss after mini-batch   211: 8.335\n",
      "Loss after mini-batch   221: 5.881\n",
      "Loss after mini-batch   231: 0.155\n",
      "Loss after mini-batch   241: 0.270\n",
      "Loss after mini-batch   251: 2.460\n",
      "Loss after mini-batch   261: 0.411\n",
      "Loss after mini-batch   271: 0.214\n",
      "Loss after mini-batch   281: 0.086\n",
      "Loss after mini-batch   291: 0.441\n",
      "Loss after mini-batch   301: 0.394\n",
      "Loss after mini-batch   311: 57.028\n",
      "Loss after mini-batch   321: 2.060\n",
      "Loss after mini-batch   331: 3.644\n",
      "Loss after mini-batch   341: 0.380\n",
      "Loss after mini-batch   351: 63.043\n",
      "Loss after mini-batch   361: 0.257\n",
      "Loss after mini-batch   371: 0.196\n",
      "Loss after mini-batch   381: 2.051\n",
      "Loss after mini-batch   391: 0.336\n",
      "Training Loss: 3.269 \t\t Validation Loss:3.761\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 5.912\n",
      "Loss after mini-batch    11: 0.585\n",
      "Loss after mini-batch    21: 0.353\n",
      "Loss after mini-batch    31: 35.103\n",
      "Loss after mini-batch    41: 0.642\n",
      "Loss after mini-batch    51: 0.569\n",
      "Loss after mini-batch    61: 3.255\n",
      "Loss after mini-batch    71: 0.711\n",
      "Loss after mini-batch    81: 9.403\n",
      "Loss after mini-batch    91: 17.438\n",
      "Loss after mini-batch   101: 0.219\n",
      "Loss after mini-batch   111: 0.351\n",
      "Loss after mini-batch   121: 0.482\n",
      "Loss after mini-batch   131: 0.313\n",
      "Loss after mini-batch   141: 56.898\n",
      "Loss after mini-batch   151: 3.553\n",
      "Loss after mini-batch   161: 59.029\n",
      "Loss after mini-batch   171: 0.129\n",
      "Loss after mini-batch   181: 0.449\n",
      "Loss after mini-batch   191: 8.161\n",
      "Loss after mini-batch   201: 0.538\n",
      "Loss after mini-batch   211: 5.213\n",
      "Loss after mini-batch   221: 11.407\n",
      "Loss after mini-batch   231: 0.351\n",
      "Loss after mini-batch   241: 14.005\n",
      "Loss after mini-batch   251: 1.961\n",
      "Loss after mini-batch   261: 26.367\n",
      "Loss after mini-batch   271: 22.699\n",
      "Loss after mini-batch   281: 17.572\n",
      "Loss after mini-batch   291: 0.839\n",
      "Loss after mini-batch   301: 1.354\n",
      "Loss after mini-batch   311: 0.739\n",
      "Loss after mini-batch   321: 0.140\n",
      "Loss after mini-batch   331: 0.447\n",
      "Loss after mini-batch   341: 0.578\n",
      "Loss after mini-batch   351: 0.457\n",
      "Loss after mini-batch   361: 20.234\n",
      "Loss after mini-batch   371: 62.838\n",
      "Loss after mini-batch   381: 8.853\n",
      "Loss after mini-batch   391: 0.184\n",
      "Training Loss: 9.116 \t\t Validation Loss:12.189\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.892\n",
      "Loss after mini-batch    11: 12.960\n",
      "Loss after mini-batch    21: 22.692\n",
      "Loss after mini-batch    31: 7.089\n",
      "Loss after mini-batch    41: 1.588\n",
      "Loss after mini-batch    51: 0.785\n",
      "Loss after mini-batch    61: 0.107\n",
      "Loss after mini-batch    71: 0.875\n",
      "Loss after mini-batch    81: 1.003\n",
      "Loss after mini-batch    91: 0.805\n",
      "Loss after mini-batch   101: 15.967\n",
      "Loss after mini-batch   111: 1.287\n",
      "Loss after mini-batch   121: 0.715\n",
      "Loss after mini-batch   131: 0.252\n",
      "Loss after mini-batch   141: 1.844\n",
      "Loss after mini-batch   151: 0.801\n",
      "Loss after mini-batch   161: 1.493\n",
      "Loss after mini-batch   171: 0.392\n",
      "Loss after mini-batch   181: 0.345\n",
      "Loss after mini-batch   191: 1.737\n",
      "Loss after mini-batch   201: 0.514\n",
      "Loss after mini-batch   211: 0.485\n",
      "Loss after mini-batch   221: 0.512\n",
      "Loss after mini-batch   231: 0.552\n",
      "Loss after mini-batch   241: 0.603\n",
      "Loss after mini-batch   251: 0.364\n",
      "Loss after mini-batch   261: 0.424\n",
      "Loss after mini-batch   271: 1.485\n",
      "Loss after mini-batch   281: 0.707\n",
      "Loss after mini-batch   291: 0.697\n",
      "Loss after mini-batch   301: 0.627\n",
      "Loss after mini-batch   311: 0.576\n",
      "Loss after mini-batch   321: 11.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   331: 1.455\n",
      "Loss after mini-batch   341: 0.103\n",
      "Loss after mini-batch   351: 0.591\n",
      "Loss after mini-batch   361: 12.811\n",
      "Loss after mini-batch   371: 0.541\n",
      "Loss after mini-batch   381: 55.838\n",
      "Loss after mini-batch   391: 1.400\n",
      "Training Loss: 0.381 \t\t Validation Loss:5.037\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 7.435\n",
      "Loss after mini-batch    11: 0.296\n",
      "Loss after mini-batch    21: 0.613\n",
      "Loss after mini-batch    31: 3.350\n",
      "Loss after mini-batch    41: 5.507\n",
      "Loss after mini-batch    51: 5.870\n",
      "Loss after mini-batch    61: 0.875\n",
      "Loss after mini-batch    71: 14.708\n",
      "Loss after mini-batch    81: 0.725\n",
      "Loss after mini-batch    91: 0.520\n",
      "Loss after mini-batch   101: 0.735\n",
      "Loss after mini-batch   111: 13.797\n",
      "Loss after mini-batch   121: 0.604\n",
      "Loss after mini-batch   131: 0.315\n",
      "Loss after mini-batch   141: 0.552\n",
      "Loss after mini-batch   151: 0.503\n",
      "Loss after mini-batch   161: 9.237\n",
      "Loss after mini-batch   171: 1.522\n",
      "Loss after mini-batch   181: 0.745\n",
      "Loss after mini-batch   191: 1.943\n",
      "Loss after mini-batch   201: 0.897\n",
      "Loss after mini-batch   211: 0.630\n",
      "Loss after mini-batch   221: 0.348\n",
      "Loss after mini-batch   231: 0.627\n",
      "Loss after mini-batch   241: 0.167\n",
      "Loss after mini-batch   251: 0.587\n",
      "Loss after mini-batch   261: 0.354\n",
      "Loss after mini-batch   271: 8.006\n",
      "Loss after mini-batch   281: 0.077\n",
      "Loss after mini-batch   291: 0.676\n",
      "Loss after mini-batch   301: 1.090\n",
      "Loss after mini-batch   311: 17.319\n",
      "Loss after mini-batch   321: 0.866\n",
      "Loss after mini-batch   331: 0.744\n",
      "Loss after mini-batch   341: 0.883\n",
      "Loss after mini-batch   351: 0.609\n",
      "Loss after mini-batch   361: 0.187\n",
      "Loss after mini-batch   371: 19.883\n",
      "Loss after mini-batch   381: 1.075\n",
      "Loss after mini-batch   391: 0.120\n",
      "Training Loss: 20.323 \t\t Validation Loss:20.326\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.064\n",
      "Loss after mini-batch    11: 20.038\n",
      "Loss after mini-batch    21: 0.199\n",
      "Loss after mini-batch    31: 0.341\n",
      "Loss after mini-batch    41: 45.089\n",
      "Loss after mini-batch    51: 0.628\n",
      "Loss after mini-batch    61: 0.301\n",
      "Loss after mini-batch    71: 0.547\n",
      "Loss after mini-batch    81: 4.726\n",
      "Loss after mini-batch    91: 20.161\n",
      "Loss after mini-batch   101: 0.480\n",
      "Loss after mini-batch   111: 0.178\n",
      "Loss after mini-batch   121: 1.238\n",
      "Loss after mini-batch   131: 0.734\n",
      "Loss after mini-batch   141: 1.287\n",
      "Loss after mini-batch   151: 10.166\n",
      "Loss after mini-batch   161: 2.028\n",
      "Loss after mini-batch   171: 0.225\n",
      "Loss after mini-batch   181: 0.709\n",
      "Loss after mini-batch   191: 0.750\n",
      "Loss after mini-batch   201: 0.472\n",
      "Loss after mini-batch   211: 0.163\n",
      "Loss after mini-batch   221: 0.343\n",
      "Loss after mini-batch   231: 0.453\n",
      "Loss after mini-batch   241: 0.297\n",
      "Loss after mini-batch   251: 0.505\n",
      "Loss after mini-batch   261: 1.584\n",
      "Loss after mini-batch   271: 54.885\n",
      "Loss after mini-batch   281: 0.794\n",
      "Loss after mini-batch   291: 0.627\n",
      "Loss after mini-batch   301: 0.242\n",
      "Loss after mini-batch   311: 0.499\n",
      "Loss after mini-batch   321: 1.098\n",
      "Loss after mini-batch   331: 15.436\n",
      "Loss after mini-batch   341: 0.566\n",
      "Loss after mini-batch   351: 8.156\n",
      "Loss after mini-batch   361: 0.453\n",
      "Loss after mini-batch   371: 40.970\n",
      "Loss after mini-batch   381: 2.219\n",
      "Loss after mini-batch   391: 0.626\n",
      "Training Loss: 0.295 \t\t Validation Loss:0.981\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 5.521\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    21: 0.686\n",
      "Loss after mini-batch    31: 0.585\n",
      "Loss after mini-batch    41: 11.282\n",
      "Loss after mini-batch    51: 0.160\n",
      "Loss after mini-batch    61: 0.530\n",
      "Loss after mini-batch    71: 0.129\n",
      "Loss after mini-batch    81: 0.234\n",
      "Loss after mini-batch    91: 0.109\n",
      "Loss after mini-batch   101: 0.649\n",
      "Loss after mini-batch   111: 0.535\n",
      "Loss after mini-batch   121: 7.398\n",
      "Loss after mini-batch   131: 0.526\n",
      "Loss after mini-batch   141: 0.535\n",
      "Loss after mini-batch   151: 0.147\n",
      "Loss after mini-batch   161: 0.702\n",
      "Loss after mini-batch   171: 55.347\n",
      "Loss after mini-batch   181: 0.709\n",
      "Loss after mini-batch   191: 1.172\n",
      "Loss after mini-batch   201: 0.257\n",
      "Loss after mini-batch   211: 2.912\n",
      "Loss after mini-batch   221: 16.487\n",
      "Loss after mini-batch   231: 0.672\n",
      "Loss after mini-batch   241: 0.775\n",
      "Loss after mini-batch   251: 0.866\n",
      "Loss after mini-batch   261: 0.715\n",
      "Loss after mini-batch   271: 0.443\n",
      "Loss after mini-batch   281: 0.736\n",
      "Loss after mini-batch   291: 5.238\n",
      "Loss after mini-batch   301: 8.767\n",
      "Loss after mini-batch   311: 0.070\n",
      "Loss after mini-batch   321: 0.615\n",
      "Loss after mini-batch   331: 15.899\n",
      "Loss after mini-batch   341: 0.760\n",
      "Loss after mini-batch   351: 1.007\n",
      "Loss after mini-batch   361: 0.591\n",
      "Loss after mini-batch   371: 0.510\n",
      "Loss after mini-batch   381: 0.583\n",
      "Loss after mini-batch   391: 0.405\n",
      "Training Loss: 5.495 \t\t Validation Loss:6.257\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 6.992\n",
      "Loss after mini-batch    11: 0.689\n",
      "Loss after mini-batch    21: 1.393\n",
      "Loss after mini-batch    31: 4.379\n",
      "Loss after mini-batch    41: 0.748\n",
      "Loss after mini-batch    51: 0.800\n",
      "Loss after mini-batch    61: 27.616\n",
      "Loss after mini-batch    71: 0.473\n",
      "Loss after mini-batch    81: 3.472\n",
      "Loss after mini-batch    91: 0.560\n",
      "Loss after mini-batch   101: 0.509\n",
      "Loss after mini-batch   111: 3.780\n",
      "Loss after mini-batch   121: 5.510\n",
      "Loss after mini-batch   131: 0.121\n",
      "Loss after mini-batch   141: 0.118\n",
      "Loss after mini-batch   151: 0.632\n",
      "Loss after mini-batch   161: 3.865\n",
      "Loss after mini-batch   171: 0.384\n",
      "Loss after mini-batch   181: 19.806\n",
      "Loss after mini-batch   191: 0.058\n",
      "Loss after mini-batch   201: 0.615\n",
      "Loss after mini-batch   211: 0.529\n",
      "Loss after mini-batch   221: 22.416\n",
      "Loss after mini-batch   231: 0.517\n",
      "Loss after mini-batch   241: 1.923\n",
      "Loss after mini-batch   251: 1.119\n",
      "Loss after mini-batch   261: 0.142\n",
      "Loss after mini-batch   271: 0.632\n",
      "Loss after mini-batch   281: 5.528\n",
      "Loss after mini-batch   291: 0.585\n",
      "Loss after mini-batch   301: 0.342\n",
      "Loss after mini-batch   311: 1.259\n",
      "Loss after mini-batch   321: 0.562\n",
      "Loss after mini-batch   331: 2.241\n",
      "Loss after mini-batch   341: 10.895\n",
      "Loss after mini-batch   351: 2.195\n",
      "Loss after mini-batch   361: 8.842\n",
      "Loss after mini-batch   371: 8.328\n",
      "Loss after mini-batch   381: 2.485\n",
      "Loss after mini-batch   391: 0.646\n",
      "Training Loss: 5.470 \t\t Validation Loss:6.031\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.227\n",
      "Loss after mini-batch    11: 0.741\n",
      "Loss after mini-batch    21: 0.629\n",
      "Loss after mini-batch    31: 0.216\n",
      "Loss after mini-batch    41: 0.996\n",
      "Loss after mini-batch    51: 9.639\n",
      "Loss after mini-batch    61: 0.868\n",
      "Loss after mini-batch    71: 0.728\n",
      "Loss after mini-batch    81: 0.776\n",
      "Loss after mini-batch    91: 19.363\n",
      "Loss after mini-batch   101: 0.237\n",
      "Loss after mini-batch   111: 6.400\n",
      "Loss after mini-batch   121: 1.921\n",
      "Loss after mini-batch   131: 0.276\n",
      "Loss after mini-batch   141: 0.630\n",
      "Loss after mini-batch   151: 0.615\n",
      "Loss after mini-batch   161: 0.697\n",
      "Loss after mini-batch   171: 5.488\n",
      "Loss after mini-batch   181: 1.221\n",
      "Loss after mini-batch   191: 0.218\n",
      "Loss after mini-batch   201: 11.498\n",
      "Loss after mini-batch   211: 0.688\n",
      "Loss after mini-batch   221: 0.852\n",
      "Loss after mini-batch   231: 0.917\n",
      "Loss after mini-batch   241: 44.553\n",
      "Loss after mini-batch   251: 0.046\n",
      "Loss after mini-batch   261: 0.764\n",
      "Loss after mini-batch   271: 3.588\n",
      "Loss after mini-batch   281: 1.165\n",
      "Loss after mini-batch   291: 3.176\n",
      "Loss after mini-batch   301: 27.647\n",
      "Loss after mini-batch   311: 0.239\n",
      "Loss after mini-batch   321: 1.823\n",
      "Loss after mini-batch   331: 0.356\n",
      "Loss after mini-batch   341: 0.042\n",
      "Loss after mini-batch   351: 0.425\n",
      "Loss after mini-batch   361: 0.156\n",
      "Loss after mini-batch   371: 0.420\n",
      "Loss after mini-batch   381: 30.184\n",
      "Loss after mini-batch   391: 8.291\n",
      "Training Loss: 0.683 \t\t Validation Loss:0.897\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.794\n",
      "Loss after mini-batch    11: 0.159\n",
      "Loss after mini-batch    21: 1.755\n",
      "Loss after mini-batch    31: 0.056\n",
      "Loss after mini-batch    41: 0.635\n",
      "Loss after mini-batch    51: 8.700\n",
      "Loss after mini-batch    61: 0.557\n",
      "Loss after mini-batch    71: 0.448\n",
      "Loss after mini-batch    81: 0.250\n",
      "Loss after mini-batch    91: 0.371\n",
      "Loss after mini-batch   101: 0.081\n",
      "Loss after mini-batch   111: 0.278\n",
      "Loss after mini-batch   121: 0.040\n",
      "Loss after mini-batch   131: 11.100\n",
      "Loss after mini-batch   141: 0.729\n",
      "Loss after mini-batch   151: 3.355\n",
      "Loss after mini-batch   161: 2.980\n",
      "Loss after mini-batch   171: 0.894\n",
      "Loss after mini-batch   181: 0.522\n",
      "Loss after mini-batch   191: 0.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   201: 0.329\n",
      "Loss after mini-batch   211: 0.213\n",
      "Loss after mini-batch   221: 0.319\n",
      "Loss after mini-batch   231: 0.234\n",
      "Loss after mini-batch   241: 13.951\n",
      "Loss after mini-batch   251: 0.454\n",
      "Loss after mini-batch   261: 0.523\n",
      "Loss after mini-batch   271: 0.499\n",
      "Loss after mini-batch   281: 0.110\n",
      "Loss after mini-batch   291: 0.949\n",
      "Loss after mini-batch   301: 1.269\n",
      "Loss after mini-batch   311: 0.744\n",
      "Loss after mini-batch   321: 0.915\n",
      "Loss after mini-batch   331: 14.501\n",
      "Loss after mini-batch   341: 0.844\n",
      "Loss after mini-batch   351: 10.250\n",
      "Loss after mini-batch   361: 14.595\n",
      "Loss after mini-batch   371: 0.536\n",
      "Loss after mini-batch   381: 0.623\n",
      "Loss after mini-batch   391: 1.004\n",
      "Training Loss: 6.445 \t\t Validation Loss:20.575\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 12.741\n",
      "Loss after mini-batch    11: 0.610\n",
      "Loss after mini-batch    21: 0.533\n",
      "Loss after mini-batch    31: 0.588\n",
      "Loss after mini-batch    41: 1.877\n",
      "Loss after mini-batch    51: 0.655\n",
      "Loss after mini-batch    61: 27.658\n",
      "Loss after mini-batch    71: 0.751\n",
      "Loss after mini-batch    81: 0.624\n",
      "Loss after mini-batch    91: 0.768\n",
      "Loss after mini-batch   101: 0.776\n",
      "Loss after mini-batch   111: 0.691\n",
      "Loss after mini-batch   121: 2.005\n",
      "Loss after mini-batch   131: 0.674\n",
      "Loss after mini-batch   141: 2.959\n",
      "Loss after mini-batch   151: 0.664\n",
      "Loss after mini-batch   161: 13.496\n",
      "Loss after mini-batch   171: 0.020\n",
      "Loss after mini-batch   181: 0.581\n",
      "Loss after mini-batch   191: 0.260\n",
      "Loss after mini-batch   201: 0.375\n",
      "Loss after mini-batch   211: 15.260\n",
      "Loss after mini-batch   221: 0.606\n",
      "Loss after mini-batch   231: 0.167\n",
      "Loss after mini-batch   241: 3.602\n",
      "Loss after mini-batch   251: 0.698\n",
      "Loss after mini-batch   261: 0.144\n",
      "Loss after mini-batch   271: 3.690\n",
      "Loss after mini-batch   281: 1.563\n",
      "Loss after mini-batch   291: 1.070\n",
      "Loss after mini-batch   301: 10.569\n",
      "Loss after mini-batch   311: 0.478\n",
      "Loss after mini-batch   321: 0.174\n",
      "Loss after mini-batch   331: 0.317\n",
      "Loss after mini-batch   341: 0.707\n",
      "Loss after mini-batch   351: 0.440\n",
      "Loss after mini-batch   361: 17.210\n",
      "Loss after mini-batch   371: 0.114\n",
      "Loss after mini-batch   381: 58.588\n",
      "Loss after mini-batch   391: 2.173\n",
      "Training Loss: 0.750 \t\t Validation Loss:1.756\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 0.923\n",
      "Loss after mini-batch    11: 0.588\n",
      "Loss after mini-batch    21: 13.216\n",
      "Loss after mini-batch    31: 54.253\n",
      "Loss after mini-batch    41: 0.651\n",
      "Loss after mini-batch    51: 0.930\n",
      "Loss after mini-batch    61: 0.972\n",
      "Loss after mini-batch    71: 0.789\n",
      "Loss after mini-batch    81: 2.932\n",
      "Loss after mini-batch    91: 5.403\n",
      "Loss after mini-batch   101: 0.402\n",
      "Loss after mini-batch   111: 0.805\n",
      "Loss after mini-batch   121: 4.797\n",
      "Loss after mini-batch   131: 9.969\n",
      "Loss after mini-batch   141: 7.291\n",
      "Loss after mini-batch   151: 7.016\n",
      "Loss after mini-batch   161: 0.828\n",
      "Loss after mini-batch   171: 0.835\n",
      "Loss after mini-batch   181: 0.796\n",
      "Loss after mini-batch   191: 0.565\n",
      "Loss after mini-batch   201: 5.474\n",
      "Loss after mini-batch   211: 2.667\n",
      "Loss after mini-batch   221: 0.670\n",
      "Loss after mini-batch   231: 19.704\n",
      "Loss after mini-batch   241: 11.417\n",
      "Loss after mini-batch   251: 0.370\n",
      "Loss after mini-batch   261: 0.563\n",
      "Loss after mini-batch   271: 0.588\n",
      "Loss after mini-batch   281: 0.656\n",
      "Loss after mini-batch   291: 0.417\n",
      "Loss after mini-batch   301: 2.404\n",
      "Loss after mini-batch   311: 15.922\n",
      "Loss after mini-batch   321: 1.144\n",
      "Loss after mini-batch   331: 0.556\n",
      "Loss after mini-batch   341: 0.578\n",
      "Loss after mini-batch   351: 1.102\n",
      "Loss after mini-batch   361: 0.370\n",
      "Loss after mini-batch   371: 0.541\n",
      "Loss after mini-batch   381: 0.591\n",
      "Loss after mini-batch   391: 0.955\n",
      "Training Loss: 0.188 \t\t Validation Loss:26.348\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 0.458\n",
      "Loss after mini-batch    11: 0.344\n",
      "Loss after mini-batch    21: 0.344\n",
      "Loss after mini-batch    31: 0.106\n",
      "Loss after mini-batch    41: 7.478\n",
      "Loss after mini-batch    51: 7.209\n",
      "Loss after mini-batch    61: 0.311\n",
      "Loss after mini-batch    71: 28.842\n",
      "Loss after mini-batch    81: 0.350\n",
      "Loss after mini-batch    91: 8.567\n",
      "Loss after mini-batch   101: 5.565\n",
      "Loss after mini-batch   111: 12.821\n",
      "Loss after mini-batch   121: 55.689\n",
      "Loss after mini-batch   131: 0.660\n",
      "Loss after mini-batch   141: 0.601\n",
      "Loss after mini-batch   151: 16.763\n",
      "Loss after mini-batch   161: 0.066\n",
      "Loss after mini-batch   171: 0.335\n",
      "Loss after mini-batch   181: 1.577\n",
      "Loss after mini-batch   191: 21.803\n",
      "Loss after mini-batch   201: 0.676\n",
      "Loss after mini-batch   211: 0.113\n",
      "Loss after mini-batch   221: 4.371\n",
      "Loss after mini-batch   231: 29.666\n",
      "Loss after mini-batch   241: 0.735\n",
      "Loss after mini-batch   251: 31.845\n",
      "Loss after mini-batch   261: 0.262\n",
      "Loss after mini-batch   271: 19.040\n",
      "Loss after mini-batch   281: 0.182\n",
      "Loss after mini-batch   291: 0.712\n",
      "Loss after mini-batch   301: 6.489\n",
      "Loss after mini-batch   311: 0.440\n",
      "Loss after mini-batch   321: 0.426\n",
      "Loss after mini-batch   331: 0.546\n",
      "Loss after mini-batch   341: 0.427\n",
      "Loss after mini-batch   351: 48.253\n",
      "Loss after mini-batch   361: 0.435\n",
      "Loss after mini-batch   371: 25.719\n",
      "Loss after mini-batch   381: 0.486\n",
      "Loss after mini-batch   391: 0.100\n",
      "Training Loss: 0.439 \t\t Validation Loss:0.910\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.630\n",
      "Loss after mini-batch    11: 5.082\n",
      "Loss after mini-batch    21: 0.639\n",
      "Loss after mini-batch    31: 0.619\n",
      "Loss after mini-batch    41: 0.900\n",
      "Loss after mini-batch    51: 0.295\n",
      "Loss after mini-batch    61: 16.111\n",
      "Loss after mini-batch    71: 0.819\n",
      "Loss after mini-batch    81: 0.826\n",
      "Loss after mini-batch    91: 0.536\n",
      "Loss after mini-batch   101: 2.231\n",
      "Loss after mini-batch   111: 0.638\n",
      "Loss after mini-batch   121: 0.444\n",
      "Loss after mini-batch   131: 0.554\n",
      "Loss after mini-batch   141: 0.252\n",
      "Loss after mini-batch   151: 0.082\n",
      "Loss after mini-batch   161: 0.287\n",
      "Loss after mini-batch   171: 0.602\n",
      "Loss after mini-batch   181: 11.258\n",
      "Loss after mini-batch   191: 3.217\n",
      "Loss after mini-batch   201: 20.975\n",
      "Loss after mini-batch   211: 5.529\n",
      "Loss after mini-batch   221: 0.611\n",
      "Loss after mini-batch   231: 0.114\n",
      "Loss after mini-batch   241: 0.311\n",
      "Loss after mini-batch   251: 0.174\n",
      "Loss after mini-batch   261: 0.233\n",
      "Loss after mini-batch   271: 1.613\n",
      "Loss after mini-batch   281: 0.333\n",
      "Loss after mini-batch   291: 25.331\n",
      "Loss after mini-batch   301: 0.712\n",
      "Loss after mini-batch   311: 12.325\n",
      "Loss after mini-batch   321: 0.230\n",
      "Loss after mini-batch   331: 0.933\n",
      "Loss after mini-batch   341: 0.879\n",
      "Loss after mini-batch   351: 0.324\n",
      "Loss after mini-batch   361: 0.911\n",
      "Loss after mini-batch   371: 0.907\n",
      "Loss after mini-batch   381: 0.475\n",
      "Loss after mini-batch   391: 0.914\n",
      "Training Loss: 0.645 \t\t Validation Loss:54.664\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 0.582\n",
      "Loss after mini-batch    11: 0.928\n",
      "Loss after mini-batch    21: 5.592\n",
      "Loss after mini-batch    31: 0.476\n",
      "Loss after mini-batch    41: 0.576\n",
      "Loss after mini-batch    51: 0.361\n",
      "Loss after mini-batch    61: 0.474\n",
      "Loss after mini-batch    71: 1.441\n",
      "Loss after mini-batch    81: 0.081\n",
      "Loss after mini-batch    91: 13.231\n",
      "Loss after mini-batch   101: 0.291\n",
      "Loss after mini-batch   111: 0.351\n",
      "Loss after mini-batch   121: 0.106\n",
      "Loss after mini-batch   131: 0.263\n",
      "Loss after mini-batch   141: 0.460\n",
      "Loss after mini-batch   151: 0.116\n",
      "Loss after mini-batch   161: 13.984\n",
      "Loss after mini-batch   171: 0.294\n",
      "Loss after mini-batch   181: 0.409\n",
      "Loss after mini-batch   191: 0.337\n",
      "Loss after mini-batch   201: 0.706\n",
      "Loss after mini-batch   211: 0.585\n",
      "Loss after mini-batch   221: 0.206\n",
      "Loss after mini-batch   231: 2.126\n",
      "Loss after mini-batch   241: 0.725\n",
      "Loss after mini-batch   251: 1.776\n",
      "Loss after mini-batch   261: 0.278\n",
      "Loss after mini-batch   271: 1.371\n",
      "Loss after mini-batch   281: 0.276\n",
      "Loss after mini-batch   291: 0.509\n",
      "Loss after mini-batch   301: 0.383\n",
      "Loss after mini-batch   311: 0.163\n",
      "Loss after mini-batch   321: 1.630\n",
      "Loss after mini-batch   331: 0.655\n",
      "Loss after mini-batch   341: 0.274\n",
      "Loss after mini-batch   351: 0.300\n",
      "Loss after mini-batch   361: 22.068\n",
      "Loss after mini-batch   371: 4.977\n",
      "Loss after mini-batch   381: 0.419\n",
      "Loss after mini-batch   391: 16.183\n",
      "Training Loss: 0.260 \t\t Validation Loss:0.789\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.724\n",
      "Loss after mini-batch    11: 0.408\n",
      "Loss after mini-batch    21: 0.295\n",
      "Loss after mini-batch    31: 6.509\n",
      "Loss after mini-batch    41: 0.434\n",
      "Loss after mini-batch    51: 0.214\n",
      "Loss after mini-batch    61: 0.146\n",
      "Loss after mini-batch    71: 0.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch    81: 3.257\n",
      "Loss after mini-batch    91: 0.411\n",
      "Loss after mini-batch   101: 0.123\n",
      "Loss after mini-batch   111: 12.996\n",
      "Loss after mini-batch   121: 0.133\n",
      "Loss after mini-batch   131: 9.219\n",
      "Loss after mini-batch   141: 0.135\n",
      "Loss after mini-batch   151: 16.560\n",
      "Loss after mini-batch   161: 13.522\n",
      "Loss after mini-batch   171: 3.542\n",
      "Loss after mini-batch   181: 3.245\n",
      "Loss after mini-batch   191: 0.498\n",
      "Loss after mini-batch   201: 15.573\n",
      "Loss after mini-batch   211: 18.660\n",
      "Loss after mini-batch   221: 0.142\n",
      "Loss after mini-batch   231: 0.857\n",
      "Loss after mini-batch   241: 0.659\n",
      "Loss after mini-batch   251: 0.524\n",
      "Loss after mini-batch   261: 0.823\n",
      "Loss after mini-batch   271: 0.667\n",
      "Loss after mini-batch   281: 13.798\n",
      "Loss after mini-batch   291: 0.517\n",
      "Loss after mini-batch   301: 0.096\n",
      "Loss after mini-batch   311: 56.853\n",
      "Loss after mini-batch   321: 0.473\n",
      "Loss after mini-batch   331: 0.696\n",
      "Loss after mini-batch   341: 1.977\n",
      "Loss after mini-batch   351: 0.979\n",
      "Loss after mini-batch   361: 0.350\n",
      "Loss after mini-batch   371: 1.053\n",
      "Loss after mini-batch   381: 20.618\n",
      "Loss after mini-batch   391: 0.857\n",
      "Training Loss: 0.806 \t\t Validation Loss:1.050\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 0.957\n",
      "Loss after mini-batch    11: 0.760\n",
      "Loss after mini-batch    21: 6.190\n",
      "Loss after mini-batch    31: 3.117\n",
      "Loss after mini-batch    41: 61.417\n",
      "Loss after mini-batch    51: 0.779\n",
      "Loss after mini-batch    61: 2.724\n",
      "Loss after mini-batch    71: 2.597\n",
      "Loss after mini-batch    81: 20.358\n",
      "Loss after mini-batch    91: 0.710\n",
      "Loss after mini-batch   101: 0.798\n",
      "Loss after mini-batch   111: 0.024\n",
      "Loss after mini-batch   121: 0.629\n",
      "Loss after mini-batch   131: 0.250\n",
      "Loss after mini-batch   141: 0.353\n",
      "Loss after mini-batch   151: 43.663\n",
      "Loss after mini-batch   161: 0.150\n",
      "Loss after mini-batch   171: 3.463\n",
      "Loss after mini-batch   181: 0.597\n",
      "Loss after mini-batch   191: 8.837\n",
      "Loss after mini-batch   201: 18.694\n",
      "Loss after mini-batch   211: 8.815\n",
      "Loss after mini-batch   221: 0.676\n",
      "Loss after mini-batch   231: 0.712\n",
      "Loss after mini-batch   241: 53.796\n",
      "Loss after mini-batch   251: 0.481\n",
      "Loss after mini-batch   261: 0.578\n",
      "Loss after mini-batch   271: 1.366\n",
      "Loss after mini-batch   281: 0.590\n",
      "Loss after mini-batch   291: 0.273\n",
      "Loss after mini-batch   301: 1.303\n",
      "Loss after mini-batch   311: 0.352\n",
      "Loss after mini-batch   321: 0.508\n",
      "Loss after mini-batch   331: 0.709\n",
      "Loss after mini-batch   341: 0.493\n",
      "Loss after mini-batch   351: 0.433\n",
      "Loss after mini-batch   361: 0.258\n",
      "Loss after mini-batch   371: 1.816\n",
      "Loss after mini-batch   381: 0.346\n",
      "Loss after mini-batch   391: 0.152\n",
      "Training Loss: 3.522 \t\t Validation Loss:3.525\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.321\n",
      "Loss after mini-batch    11: 2.592\n",
      "Loss after mini-batch    21: 0.367\n",
      "Loss after mini-batch    31: 0.262\n",
      "Loss after mini-batch    41: 0.355\n",
      "Loss after mini-batch    51: 13.703\n",
      "Loss after mini-batch    61: 0.219\n",
      "Loss after mini-batch    71: 0.135\n",
      "Loss after mini-batch    81: 4.216\n",
      "Loss after mini-batch    91: 1.792\n",
      "Loss after mini-batch   101: 7.825\n",
      "Loss after mini-batch   111: 8.837\n",
      "Loss after mini-batch   121: 1.585\n",
      "Loss after mini-batch   131: 0.043\n",
      "Loss after mini-batch   141: 0.036\n",
      "Loss after mini-batch   151: 0.564\n",
      "Loss after mini-batch   161: 0.887\n",
      "Loss after mini-batch   171: 0.225\n",
      "Loss after mini-batch   181: 13.051\n",
      "Loss after mini-batch   191: 0.271\n",
      "Loss after mini-batch   201: 0.828\n",
      "Loss after mini-batch   211: 29.084\n",
      "Loss after mini-batch   221: 0.626\n",
      "Loss after mini-batch   231: 0.895\n",
      "Loss after mini-batch   241: 0.866\n",
      "Loss after mini-batch   251: 0.759\n",
      "Loss after mini-batch   261: 0.732\n",
      "Loss after mini-batch   271: 0.534\n",
      "Loss after mini-batch   281: 14.524\n",
      "Loss after mini-batch   291: 0.218\n",
      "Loss after mini-batch   301: 2.009\n",
      "Loss after mini-batch   311: 2.868\n",
      "Loss after mini-batch   321: 0.075\n",
      "Loss after mini-batch   331: 0.292\n",
      "Loss after mini-batch   341: 3.523\n",
      "Loss after mini-batch   351: 10.254\n",
      "Loss after mini-batch   361: 0.600\n",
      "Loss after mini-batch   371: 12.379\n",
      "Loss after mini-batch   381: 0.390\n",
      "Loss after mini-batch   391: 0.296\n",
      "Training Loss: 0.345 \t\t Validation Loss:0.686\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 2.227\n",
      "Loss after mini-batch    11: 0.533\n",
      "Loss after mini-batch    21: 0.162\n",
      "Loss after mini-batch    31: 0.443\n",
      "Loss after mini-batch    41: 0.156\n",
      "Loss after mini-batch    51: 0.263\n",
      "Loss after mini-batch    61: 0.290\n",
      "Loss after mini-batch    71: 0.116\n",
      "Loss after mini-batch    81: 0.315\n",
      "Loss after mini-batch    91: 4.186\n",
      "Loss after mini-batch   101: 0.076\n",
      "Loss after mini-batch   111: 0.503\n",
      "Loss after mini-batch   121: 0.411\n",
      "Loss after mini-batch   131: 0.493\n",
      "Loss after mini-batch   141: 21.513\n",
      "Loss after mini-batch   151: 34.803\n",
      "Loss after mini-batch   161: 47.485\n",
      "Loss after mini-batch   171: 0.564\n",
      "Loss after mini-batch   181: 0.592\n",
      "Loss after mini-batch   191: 1.954\n",
      "Loss after mini-batch   201: 0.547\n",
      "Loss after mini-batch   211: 6.324\n",
      "Loss after mini-batch   221: 0.082\n",
      "Loss after mini-batch   231: 0.439\n",
      "Loss after mini-batch   241: 0.529\n",
      "Loss after mini-batch   251: 6.120\n",
      "Loss after mini-batch   261: 0.181\n",
      "Loss after mini-batch   271: 10.825\n",
      "Loss after mini-batch   281: 3.042\n",
      "Loss after mini-batch   291: 0.895\n",
      "Loss after mini-batch   301: 6.999\n",
      "Loss after mini-batch   311: 0.787\n",
      "Loss after mini-batch   321: 2.826\n",
      "Loss after mini-batch   331: 6.302\n",
      "Loss after mini-batch   341: 14.005\n",
      "Loss after mini-batch   351: 0.553\n",
      "Loss after mini-batch   361: 1.428\n",
      "Loss after mini-batch   371: 0.526\n",
      "Loss after mini-batch   381: 0.567\n",
      "Loss after mini-batch   391: 5.192\n",
      "Training Loss: 0.026 \t\t Validation Loss:6.458\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 43.509\n",
      "Loss after mini-batch    11: 0.296\n",
      "Loss after mini-batch    21: 1.001\n",
      "Loss after mini-batch    31: 0.107\n",
      "Loss after mini-batch    41: 13.512\n",
      "Loss after mini-batch    51: 0.483\n",
      "Loss after mini-batch    61: 1.466\n",
      "Loss after mini-batch    71: 0.330\n",
      "Loss after mini-batch    81: 0.814\n",
      "Loss after mini-batch    91: 0.711\n",
      "Loss after mini-batch   101: 0.526\n",
      "Loss after mini-batch   111: 0.414\n",
      "Loss after mini-batch   121: 0.512\n",
      "Loss after mini-batch   131: 12.724\n",
      "Loss after mini-batch   141: 4.362\n",
      "Loss after mini-batch   151: 3.492\n",
      "Loss after mini-batch   161: 0.581\n",
      "Loss after mini-batch   171: 0.642\n",
      "Loss after mini-batch   181: 0.586\n",
      "Loss after mini-batch   191: 2.960\n",
      "Loss after mini-batch   201: 53.426\n",
      "Loss after mini-batch   211: 0.421\n",
      "Loss after mini-batch   221: 10.539\n",
      "Loss after mini-batch   231: 0.464\n",
      "Loss after mini-batch   241: 0.013\n",
      "Loss after mini-batch   251: 0.208\n",
      "Loss after mini-batch   261: 0.043\n",
      "Loss after mini-batch   271: 0.293\n",
      "Loss after mini-batch   281: 0.427\n",
      "Loss after mini-batch   291: 0.548\n",
      "Loss after mini-batch   301: 13.100\n",
      "Loss after mini-batch   311: 0.873\n",
      "Loss after mini-batch   321: 0.603\n",
      "Loss after mini-batch   331: 9.065\n",
      "Loss after mini-batch   341: 0.648\n",
      "Loss after mini-batch   351: 0.796\n",
      "Loss after mini-batch   361: 0.517\n",
      "Loss after mini-batch   371: 3.273\n",
      "Loss after mini-batch   381: 0.653\n",
      "Loss after mini-batch   391: 0.255\n",
      "Training Loss: 2.459 \t\t Validation Loss:2.542\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 0.271\n",
      "Loss after mini-batch    11: 3.266\n",
      "Loss after mini-batch    21: 0.255\n",
      "Loss after mini-batch    31: 0.343\n",
      "Loss after mini-batch    41: 0.209\n",
      "Loss after mini-batch    51: 0.108\n",
      "Loss after mini-batch    61: 0.272\n",
      "Loss after mini-batch    71: 0.332\n",
      "Loss after mini-batch    81: 0.858\n",
      "Loss after mini-batch    91: 0.014\n",
      "Loss after mini-batch   101: 0.337\n",
      "Loss after mini-batch   111: 0.309\n",
      "Loss after mini-batch   121: 0.329\n",
      "Loss after mini-batch   131: 15.530\n",
      "Loss after mini-batch   141: 0.610\n",
      "Loss after mini-batch   151: 0.204\n",
      "Loss after mini-batch   161: 1.602\n",
      "Loss after mini-batch   171: 1.607\n",
      "Loss after mini-batch   181: 0.510\n",
      "Loss after mini-batch   191: 4.136\n",
      "Loss after mini-batch   201: 0.316\n",
      "Loss after mini-batch   211: 7.748\n",
      "Loss after mini-batch   221: 3.734\n",
      "Loss after mini-batch   231: 5.376\n",
      "Loss after mini-batch   241: 54.537\n",
      "Loss after mini-batch   251: 0.729\n",
      "Loss after mini-batch   261: 0.560\n",
      "Loss after mini-batch   271: 11.403\n",
      "Loss after mini-batch   281: 8.052\n",
      "Loss after mini-batch   291: 8.599\n",
      "Loss after mini-batch   301: 0.519\n",
      "Loss after mini-batch   311: 0.411\n",
      "Loss after mini-batch   321: 1.162\n",
      "Loss after mini-batch   331: 0.453\n",
      "Loss after mini-batch   341: 0.188\n",
      "Loss after mini-batch   351: 0.436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   361: 0.672\n",
      "Loss after mini-batch   371: 9.342\n",
      "Loss after mini-batch   381: 0.349\n",
      "Loss after mini-batch   391: 9.198\n",
      "Training Loss: 5.205 \t\t Validation Loss:5.478\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 0.200\n",
      "Loss after mini-batch    11: 14.655\n",
      "Loss after mini-batch    21: 0.142\n",
      "Loss after mini-batch    31: 0.049\n",
      "Loss after mini-batch    41: 0.262\n",
      "Loss after mini-batch    51: 6.887\n",
      "Loss after mini-batch    61: 0.226\n",
      "Loss after mini-batch    71: 0.530\n",
      "Loss after mini-batch    81: 0.898\n",
      "Loss after mini-batch    91: 3.184\n",
      "Loss after mini-batch   101: 0.917\n",
      "Loss after mini-batch   111: 1.020\n",
      "Loss after mini-batch   121: 12.679\n",
      "Loss after mini-batch   131: 0.525\n",
      "Loss after mini-batch   141: 1.070\n",
      "Loss after mini-batch   151: 0.551\n",
      "Loss after mini-batch   161: 0.368\n",
      "Loss after mini-batch   171: 17.494\n",
      "Loss after mini-batch   181: 0.323\n",
      "Loss after mini-batch   191: 0.851\n",
      "Loss after mini-batch   201: 0.513\n",
      "Loss after mini-batch   211: 8.948\n",
      "Loss after mini-batch   221: 0.047\n",
      "Loss after mini-batch   231: 0.552\n",
      "Loss after mini-batch   241: 5.541\n",
      "Loss after mini-batch   251: 7.240\n",
      "Loss after mini-batch   261: 0.792\n",
      "Loss after mini-batch   271: 0.427\n",
      "Loss after mini-batch   281: 0.377\n",
      "Loss after mini-batch   291: 5.333\n",
      "Loss after mini-batch   301: 0.340\n",
      "Loss after mini-batch   311: 0.340\n",
      "Loss after mini-batch   321: 21.398\n",
      "Loss after mini-batch   331: 0.185\n",
      "Loss after mini-batch   341: 0.306\n",
      "Loss after mini-batch   351: 0.220\n",
      "Loss after mini-batch   361: 0.652\n",
      "Loss after mini-batch   371: 60.718\n",
      "Loss after mini-batch   381: 0.587\n",
      "Loss after mini-batch   391: 7.692\n",
      "Training Loss: 0.499 \t\t Validation Loss:0.865\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.555\n",
      "Loss after mini-batch    11: 4.164\n",
      "Loss after mini-batch    21: 3.126\n",
      "Loss after mini-batch    31: 29.090\n",
      "Loss after mini-batch    41: 0.559\n",
      "Loss after mini-batch    51: 0.459\n",
      "Loss after mini-batch    61: 0.402\n",
      "Loss after mini-batch    71: 3.857\n",
      "Loss after mini-batch    81: 0.023\n",
      "Loss after mini-batch    91: 14.410\n",
      "Loss after mini-batch   101: 81.580\n",
      "Loss after mini-batch   111: 0.243\n",
      "Loss after mini-batch   121: 0.549\n",
      "Loss after mini-batch   131: 0.494\n",
      "Loss after mini-batch   141: 0.266\n",
      "Loss after mini-batch   151: 2.310\n",
      "Loss after mini-batch   161: 0.389\n",
      "Loss after mini-batch   171: 0.620\n",
      "Loss after mini-batch   181: 0.509\n",
      "Loss after mini-batch   191: 5.995\n",
      "Loss after mini-batch   201: 0.372\n",
      "Loss after mini-batch   211: 0.326\n",
      "Loss after mini-batch   221: 0.167\n",
      "Loss after mini-batch   231: 0.100\n",
      "Loss after mini-batch   241: 0.219\n",
      "Loss after mini-batch   251: 2.891\n",
      "Loss after mini-batch   261: 0.166\n",
      "Loss after mini-batch   271: 1.899\n",
      "Loss after mini-batch   281: 0.403\n",
      "Loss after mini-batch   291: 0.603\n",
      "Loss after mini-batch   301: 0.153\n",
      "Loss after mini-batch   311: 0.343\n",
      "Loss after mini-batch   321: 0.925\n",
      "Loss after mini-batch   331: 0.557\n",
      "Loss after mini-batch   341: 0.482\n",
      "Loss after mini-batch   351: 7.375\n",
      "Loss after mini-batch   361: 0.583\n",
      "Loss after mini-batch   371: 0.290\n",
      "Loss after mini-batch   381: 0.420\n",
      "Loss after mini-batch   391: 0.376\n",
      "Training Loss: 2.973 \t\t Validation Loss:15.748\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 0.449\n",
      "Loss after mini-batch    11: 5.082\n",
      "Loss after mini-batch    21: 0.502\n",
      "Loss after mini-batch    31: 0.321\n",
      "Loss after mini-batch    41: 0.564\n",
      "Loss after mini-batch    51: 0.623\n",
      "Loss after mini-batch    61: 0.571\n",
      "Loss after mini-batch    71: 0.359\n",
      "Loss after mini-batch    81: 11.400\n",
      "Loss after mini-batch    91: 0.426\n",
      "Loss after mini-batch   101: 0.322\n",
      "Loss after mini-batch   111: 7.691\n",
      "Loss after mini-batch   121: 0.317\n",
      "Loss after mini-batch   131: 1.810\n",
      "Loss after mini-batch   141: 0.014\n",
      "Loss after mini-batch   151: 0.450\n",
      "Loss after mini-batch   161: 0.732\n",
      "Loss after mini-batch   171: 24.784\n",
      "Loss after mini-batch   181: 0.320\n",
      "Loss after mini-batch   191: 1.544\n",
      "Loss after mini-batch   201: 9.839\n",
      "Loss after mini-batch   211: 0.592\n",
      "Loss after mini-batch   221: 3.158\n",
      "Loss after mini-batch   231: 0.688\n",
      "Loss after mini-batch   241: 18.322\n",
      "Loss after mini-batch   251: 0.562\n",
      "Loss after mini-batch   261: 0.138\n",
      "Loss after mini-batch   271: 0.404\n",
      "Loss after mini-batch   281: 25.665\n",
      "Loss after mini-batch   291: 0.134\n",
      "Loss after mini-batch   301: 10.034\n",
      "Loss after mini-batch   311: 3.087\n",
      "Loss after mini-batch   321: 0.972\n",
      "Loss after mini-batch   331: 7.957\n",
      "Loss after mini-batch   341: 0.450\n",
      "Loss after mini-batch   351: 0.814\n",
      "Loss after mini-batch   361: 1.036\n",
      "Loss after mini-batch   371: 0.745\n",
      "Loss after mini-batch   381: 6.699\n",
      "Loss after mini-batch   391: 2.418\n",
      "Training Loss: 0.467 \t\t Validation Loss:1.181\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 1.038\n",
      "Loss after mini-batch    11: 1.454\n",
      "Loss after mini-batch    21: 0.173\n",
      "Loss after mini-batch    31: 0.221\n",
      "Loss after mini-batch    41: 2.510\n",
      "Loss after mini-batch    51: 1.223\n",
      "Loss after mini-batch    61: 1.513\n",
      "Loss after mini-batch    71: 0.893\n",
      "Loss after mini-batch    81: 0.773\n",
      "Loss after mini-batch    91: 60.611\n",
      "Loss after mini-batch   101: 0.382\n",
      "Loss after mini-batch   111: 0.192\n",
      "Loss after mini-batch   121: 0.625\n",
      "Loss after mini-batch   131: 0.113\n",
      "Loss after mini-batch   141: 0.168\n",
      "Loss after mini-batch   151: 4.786\n",
      "Loss after mini-batch   161: 0.101\n",
      "Loss after mini-batch   171: 1.974\n",
      "Loss after mini-batch   181: 0.016\n",
      "Loss after mini-batch   191: 5.242\n",
      "Loss after mini-batch   201: 0.526\n",
      "Loss after mini-batch   211: 52.698\n",
      "Loss after mini-batch   221: 9.020\n",
      "Loss after mini-batch   231: 5.857\n",
      "Loss after mini-batch   241: 0.391\n",
      "Loss after mini-batch   251: 0.163\n",
      "Loss after mini-batch   261: 4.915\n",
      "Loss after mini-batch   271: 0.815\n",
      "Loss after mini-batch   281: 0.547\n",
      "Loss after mini-batch   291: 0.277\n",
      "Loss after mini-batch   301: 0.873\n",
      "Loss after mini-batch   311: 1.738\n",
      "Loss after mini-batch   321: 1.778\n",
      "Loss after mini-batch   331: 0.837\n",
      "Loss after mini-batch   341: 0.393\n",
      "Loss after mini-batch   351: 0.301\n",
      "Loss after mini-batch   361: 26.785\n",
      "Loss after mini-batch   371: 14.161\n",
      "Loss after mini-batch   381: 12.601\n",
      "Loss after mini-batch   391: 2.974\n",
      "Training Loss: 0.660 \t\t Validation Loss:1.084\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 26.578\n",
      "Loss after mini-batch    11: 0.548\n",
      "Loss after mini-batch    21: 0.490\n",
      "Loss after mini-batch    31: 0.296\n",
      "Loss after mini-batch    41: 0.369\n",
      "Loss after mini-batch    51: 0.196\n",
      "Loss after mini-batch    61: 0.063\n",
      "Loss after mini-batch    71: 0.518\n",
      "Loss after mini-batch    81: 0.252\n",
      "Loss after mini-batch    91: 2.802\n",
      "Loss after mini-batch   101: 8.727\n",
      "Loss after mini-batch   111: 18.208\n",
      "Loss after mini-batch   121: 0.459\n",
      "Loss after mini-batch   131: 8.876\n",
      "Loss after mini-batch   141: 0.217\n",
      "Loss after mini-batch   151: 6.676\n",
      "Loss after mini-batch   161: 8.023\n",
      "Loss after mini-batch   171: 2.008\n",
      "Loss after mini-batch   181: 0.316\n",
      "Loss after mini-batch   191: 1.124\n",
      "Loss after mini-batch   201: 0.847\n",
      "Loss after mini-batch   211: 0.443\n",
      "Loss after mini-batch   221: 6.904\n",
      "Loss after mini-batch   231: 0.039\n",
      "Loss after mini-batch   241: 0.285\n",
      "Loss after mini-batch   251: 0.123\n",
      "Loss after mini-batch   261: 12.328\n",
      "Loss after mini-batch   271: 0.199\n",
      "Loss after mini-batch   281: 0.356\n",
      "Loss after mini-batch   291: 0.494\n",
      "Loss after mini-batch   301: 0.290\n",
      "Loss after mini-batch   311: 15.424\n",
      "Loss after mini-batch   321: 15.875\n",
      "Loss after mini-batch   331: 0.229\n",
      "Loss after mini-batch   341: 1.397\n",
      "Loss after mini-batch   351: 0.904\n",
      "Loss after mini-batch   361: 0.827\n",
      "Loss after mini-batch   371: 1.099\n",
      "Loss after mini-batch   381: 2.493\n",
      "Loss after mini-batch   391: 1.526\n",
      "Training Loss: 0.116 \t\t Validation Loss:0.468\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 1.679\n",
      "Loss after mini-batch    11: 0.349\n",
      "Loss after mini-batch    21: 13.302\n",
      "Loss after mini-batch    31: 1.055\n",
      "Loss after mini-batch    41: 8.774\n",
      "Loss after mini-batch    51: 10.849\n",
      "Loss after mini-batch    61: 56.324\n",
      "Loss after mini-batch    71: 0.371\n",
      "Loss after mini-batch    81: 0.652\n",
      "Loss after mini-batch    91: 0.965\n",
      "Loss after mini-batch   101: 0.049\n",
      "Loss after mini-batch   111: 1.247\n",
      "Loss after mini-batch   121: 5.240\n",
      "Loss after mini-batch   131: 0.663\n",
      "Loss after mini-batch   141: 0.731\n",
      "Loss after mini-batch   151: 12.862\n",
      "Loss after mini-batch   161: 4.717\n",
      "Loss after mini-batch   171: 0.481\n",
      "Loss after mini-batch   181: 0.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   191: 4.561\n",
      "Loss after mini-batch   201: 7.904\n",
      "Loss after mini-batch   211: 0.236\n",
      "Loss after mini-batch   221: 2.116\n",
      "Loss after mini-batch   231: 8.865\n",
      "Loss after mini-batch   241: 0.636\n",
      "Loss after mini-batch   251: 0.340\n",
      "Loss after mini-batch   261: 80.681\n",
      "Loss after mini-batch   271: 0.052\n",
      "Loss after mini-batch   281: 15.748\n",
      "Loss after mini-batch   291: 0.475\n",
      "Loss after mini-batch   301: 3.646\n",
      "Loss after mini-batch   311: 18.616\n",
      "Loss after mini-batch   321: 1.620\n",
      "Loss after mini-batch   331: 0.065\n",
      "Loss after mini-batch   341: 0.404\n",
      "Loss after mini-batch   351: 0.763\n",
      "Loss after mini-batch   361: 0.180\n",
      "Loss after mini-batch   371: 0.110\n",
      "Loss after mini-batch   381: 8.806\n",
      "Loss after mini-batch   391: 0.290\n",
      "Training Loss: 0.461 \t\t Validation Loss:38.026\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 39.008\n",
      "Loss after mini-batch    11: 0.467\n",
      "Loss after mini-batch    21: 0.298\n",
      "Loss after mini-batch    31: 0.223\n",
      "Loss after mini-batch    41: 14.932\n",
      "Loss after mini-batch    51: 8.144\n",
      "Loss after mini-batch    61: 0.495\n",
      "Loss after mini-batch    71: 1.088\n",
      "Loss after mini-batch    81: 6.806\n",
      "Loss after mini-batch    91: 1.142\n",
      "Loss after mini-batch   101: 0.214\n",
      "Loss after mini-batch   111: 0.593\n",
      "Loss after mini-batch   121: 0.214\n",
      "Loss after mini-batch   131: 0.028\n",
      "Loss after mini-batch   141: 0.118\n",
      "Loss after mini-batch   151: 0.801\n",
      "Loss after mini-batch   161: 12.681\n",
      "Loss after mini-batch   171: 0.098\n",
      "Loss after mini-batch   181: 2.911\n",
      "Loss after mini-batch   191: 13.231\n",
      "Loss after mini-batch   201: 1.123\n",
      "Loss after mini-batch   211: 13.699\n",
      "Loss after mini-batch   221: 0.333\n",
      "Loss after mini-batch   231: 0.979\n",
      "Loss after mini-batch   241: 1.169\n",
      "Loss after mini-batch   251: 51.854\n",
      "Loss after mini-batch   261: 0.400\n",
      "Loss after mini-batch   271: 0.709\n",
      "Loss after mini-batch   281: 0.004\n",
      "Loss after mini-batch   291: 1.066\n",
      "Loss after mini-batch   301: 0.045\n",
      "Loss after mini-batch   311: 0.322\n",
      "Loss after mini-batch   321: 0.267\n",
      "Loss after mini-batch   331: 0.111\n",
      "Loss after mini-batch   341: 12.519\n",
      "Loss after mini-batch   351: 0.720\n",
      "Loss after mini-batch   361: 0.008\n",
      "Loss after mini-batch   371: 0.128\n",
      "Loss after mini-batch   381: 7.575\n",
      "Loss after mini-batch   391: 0.386\n",
      "Training Loss: 0.425 \t\t Validation Loss:37.885\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 6.158\n",
      "Loss after mini-batch    11: 0.239\n",
      "Loss after mini-batch    21: 24.989\n",
      "Loss after mini-batch    31: 0.135\n",
      "Loss after mini-batch    41: 0.386\n",
      "Loss after mini-batch    51: 0.211\n",
      "Loss after mini-batch    61: 0.154\n",
      "Loss after mini-batch    71: 0.196\n",
      "Loss after mini-batch    81: 0.309\n",
      "Loss after mini-batch    91: 16.179\n",
      "Loss after mini-batch   101: 11.341\n",
      "Loss after mini-batch   111: 12.385\n",
      "Loss after mini-batch   121: 0.442\n",
      "Loss after mini-batch   131: 0.275\n",
      "Loss after mini-batch   141: 0.096\n",
      "Loss after mini-batch   151: 0.261\n",
      "Loss after mini-batch   161: 0.262\n",
      "Loss after mini-batch   171: 0.381\n",
      "Loss after mini-batch   181: 0.198\n",
      "Loss after mini-batch   191: 0.229\n",
      "Loss after mini-batch   201: 20.202\n",
      "Loss after mini-batch   211: 0.723\n",
      "Loss after mini-batch   221: 0.243\n",
      "Loss after mini-batch   231: 0.672\n",
      "Loss after mini-batch   241: 0.557\n",
      "Loss after mini-batch   251: 26.438\n",
      "Loss after mini-batch   261: 2.726\n",
      "Loss after mini-batch   271: 8.659\n",
      "Loss after mini-batch   281: 0.550\n",
      "Loss after mini-batch   291: 0.582\n",
      "Loss after mini-batch   301: 1.545\n",
      "Loss after mini-batch   311: 3.576\n",
      "Loss after mini-batch   321: 0.394\n",
      "Loss after mini-batch   331: 0.256\n",
      "Loss after mini-batch   341: 7.329\n",
      "Loss after mini-batch   351: 0.658\n",
      "Loss after mini-batch   361: 0.503\n",
      "Loss after mini-batch   371: 0.603\n",
      "Loss after mini-batch   381: 0.791\n",
      "Loss after mini-batch   391: 20.427\n",
      "Training Loss: 6.818 \t\t Validation Loss:7.173\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 0.474\n",
      "Loss after mini-batch    11: 4.553\n",
      "Loss after mini-batch    21: 0.815\n",
      "Loss after mini-batch    31: 59.913\n",
      "Loss after mini-batch    41: 0.230\n",
      "Loss after mini-batch    51: 80.142\n",
      "Loss after mini-batch    61: 0.333\n",
      "Loss after mini-batch    71: 0.263\n",
      "Loss after mini-batch    81: 3.839\n",
      "Loss after mini-batch    91: 57.878\n",
      "Loss after mini-batch   101: 29.163\n",
      "Loss after mini-batch   111: 4.139\n",
      "Loss after mini-batch   121: 7.691\n",
      "Loss after mini-batch   131: 0.441\n",
      "Loss after mini-batch   141: 13.237\n",
      "Loss after mini-batch   151: 18.044\n",
      "Loss after mini-batch   161: 0.005\n",
      "Loss after mini-batch   171: 0.052\n",
      "Loss after mini-batch   181: 0.106\n",
      "Loss after mini-batch   191: 0.064\n",
      "Loss after mini-batch   201: 0.625\n",
      "Loss after mini-batch   211: 0.440\n",
      "Loss after mini-batch   221: 0.386\n",
      "Loss after mini-batch   231: 7.489\n",
      "Loss after mini-batch   241: 0.374\n",
      "Loss after mini-batch   251: 2.013\n",
      "Loss after mini-batch   261: 1.939\n",
      "Loss after mini-batch   271: 0.105\n",
      "Loss after mini-batch   281: 0.051\n",
      "Loss after mini-batch   291: 13.770\n",
      "Loss after mini-batch   301: 1.201\n",
      "Loss after mini-batch   311: 0.378\n",
      "Loss after mini-batch   321: 0.578\n",
      "Loss after mini-batch   331: 0.944\n",
      "Loss after mini-batch   341: 0.060\n",
      "Loss after mini-batch   351: 0.920\n",
      "Loss after mini-batch   361: 0.893\n",
      "Loss after mini-batch   371: 0.024\n",
      "Loss after mini-batch   381: 2.345\n",
      "Loss after mini-batch   391: 2.073\n",
      "Training Loss: 0.911 \t\t Validation Loss:12.028\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 0.701\n",
      "Loss after mini-batch    11: 1.473\n",
      "Loss after mini-batch    21: 9.432\n",
      "Loss after mini-batch    31: 0.266\n",
      "Loss after mini-batch    41: 0.127\n",
      "Loss after mini-batch    51: 0.343\n",
      "Loss after mini-batch    61: 0.713\n",
      "Loss after mini-batch    71: 13.160\n",
      "Loss after mini-batch    81: 0.163\n",
      "Loss after mini-batch    91: 0.173\n",
      "Loss after mini-batch   101: 10.042\n",
      "Loss after mini-batch   111: 1.205\n",
      "Loss after mini-batch   121: 0.189\n",
      "Loss after mini-batch   131: 0.005\n",
      "Loss after mini-batch   141: 13.693\n",
      "Loss after mini-batch   151: 53.028\n",
      "Loss after mini-batch   161: 51.537\n",
      "Loss after mini-batch   171: 0.210\n",
      "Loss after mini-batch   181: 0.055\n",
      "Loss after mini-batch   191: 28.389\n",
      "Loss after mini-batch   201: 2.667\n",
      "Loss after mini-batch   211: 0.258\n",
      "Loss after mini-batch   221: 0.314\n",
      "Loss after mini-batch   231: 1.028\n",
      "Loss after mini-batch   241: 0.451\n",
      "Loss after mini-batch   251: 0.137\n",
      "Loss after mini-batch   261: 0.793\n",
      "Loss after mini-batch   271: 0.685\n",
      "Loss after mini-batch   281: 19.548\n",
      "Loss after mini-batch   291: 0.600\n",
      "Loss after mini-batch   301: 10.820\n",
      "Loss after mini-batch   311: 0.535\n",
      "Loss after mini-batch   321: 0.122\n",
      "Loss after mini-batch   331: 0.212\n",
      "Loss after mini-batch   341: 79.838\n",
      "Loss after mini-batch   351: 4.828\n",
      "Loss after mini-batch   361: 2.838\n",
      "Loss after mini-batch   371: 0.359\n",
      "Loss after mini-batch   381: 13.170\n",
      "Loss after mini-batch   391: 0.609\n",
      "Training Loss: 8.464 \t\t Validation Loss:8.671\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "history_train = np.empty((1,))\n",
    "history_val = np.empty((1,))\n",
    "nepochs=50\n",
    "for epoch in range(0, nepochs): # 5 epochs at maximum  \n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "          # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "#                 (i + 1, current_loss / 500))\n",
    "                  (i + 1, loss.item()))\n",
    "            current_loss = 0.0\n",
    "    history_train = np.append(history_train, current_loss)\n",
    "\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    mlp.eval()     # Optional when not using Model Specific layer\n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "        \n",
    "        output_val = mlp(inputs)\n",
    "        valid_loss = loss_function(output_val, targets)\n",
    "    \n",
    "        valid_loss += loss.item()\n",
    "    history_val = np.append(history_val, valid_loss.item())\n",
    "    print('Training Loss: {:.3f} \\t\\t Validation Loss:'\\\n",
    "         '{:.3f}'.format(loss.item(), valid_loss.item()))\n",
    "#     print('Training Loss: {:.3f} \\t\\t Validation Loss:'\\\n",
    "#           '{:.3f}'.format(current_loss / len(trainloader), valid_loss / len(validloader)))\n",
    "#     if min_valid_loss > valid_loss:\n",
    "#         print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "#         min_valid_loss = valid_loss\n",
    "#         # Saving State Dict\n",
    "#         torch.save(model.state_dict(), 'saved_model.pth')\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419c265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.random.randn(13)\n",
    "# torch usa tensores de torch y no numpy.darrays\n",
    "dtype = torch.float\n",
    "test = torch.randn((1, 3), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0514722",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f13290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape((y_pred*2).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b863276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.715832233428955"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6665e94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0, 0], X_test[0]\n",
    "ypred = y_pred.detach().numpy()\n",
    "ytest = y_test.detach().numpy()\n",
    "diff=np.array(ytest)-np.array(ypred)\n",
    "len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf75e18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 20.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diff,bins=100)\n",
    "plt.xscale('log')\n",
    "plt.ylim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9eb5d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbb782481f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ep = np.arange(0, nepochs+1)\n",
    "plt.plot(ep, history_train, label='train', color='green')\n",
    "plt.plot(ep, history_val, label='val', color='orange')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad66c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([54.2568]) tensor([14.0983], grad_fn=<UnbindBackward0>)\n",
      "tensor([7.2576]) tensor([7.4838], grad_fn=<UnbindBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.displot(y_test)\n",
    "plt.plot(np.sort(y_test.detach().numpy()), color='blue', label='true likelihood')\n",
    "plt.plot(np.sort(y_pred.detach().numpy()), color='red', label='neural likelihood')\n",
    "plt.ylabel('-loglikelihood')\n",
    "plt.legend()\n",
    "print(max(y_test), max(y_pred))\n",
    "print(min(y_test), min(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5df28e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51,), (51,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(history_train), np.shape(history_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b747bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 60.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ytest, bins=len(ytest), color='red')\n",
    "# plt.hist(ypred, bins=len(ypred), color='green')\n",
    "plt.ylim(0,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65b46984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ypred)==len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f1e6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8b7a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> 7.715832710266113\n",
      "<class 'torch.Tensor'> 8.485013008117676\n",
      "<class 'torch.Tensor'> 8.220362663269043\n",
      "<class 'torch.Tensor'> 7.560459136962891\n",
      "<class 'torch.Tensor'> 10.452359199523926\n",
      "<class 'torch.Tensor'> 7.569005966186523\n",
      "<class 'torch.Tensor'> 10.501705169677734\n",
      "<class 'torch.Tensor'> 7.609738349914551\n",
      "<class 'torch.Tensor'> 8.81411075592041\n",
      "<class 'torch.Tensor'> 7.564368724822998\n",
      "<class 'torch.Tensor'> 7.988768100738525\n",
      "<class 'torch.Tensor'> 7.853349685668945\n",
      "<class 'torch.Tensor'> 7.963178634643555\n",
      "<class 'torch.Tensor'> 12.507362365722656\n",
      "<class 'torch.Tensor'> 12.383030891418457\n",
      "<class 'torch.Tensor'> 13.217791557312012\n",
      "<class 'torch.Tensor'> 8.578206062316895\n",
      "<class 'torch.Tensor'> 9.37583065032959\n",
      "<class 'torch.Tensor'> 9.048086166381836\n",
      "<class 'torch.Tensor'> 7.558465003967285\n",
      "<class 'torch.Tensor'> 7.764596939086914\n",
      "<class 'torch.Tensor'> 7.560983180999756\n",
      "<class 'torch.Tensor'> 7.527746200561523\n",
      "<class 'torch.Tensor'> 8.08034610748291\n",
      "<class 'torch.Tensor'> 7.989005088806152\n",
      "<class 'torch.Tensor'> 7.620049953460693\n",
      "<class 'torch.Tensor'> 9.52719497680664\n",
      "<class 'torch.Tensor'> 7.483760833740234\n",
      "<class 'torch.Tensor'> 9.125542640686035\n",
      "<class 'torch.Tensor'> 9.559653282165527\n",
      "<class 'torch.Tensor'> 11.895095825195312\n",
      "<class 'torch.Tensor'> 8.744256973266602\n",
      "<class 'torch.Tensor'> 13.295944213867188\n",
      "<class 'torch.Tensor'> 8.597443580627441\n",
      "<class 'torch.Tensor'> 7.505169868469238\n",
      "<class 'torch.Tensor'> 11.725876808166504\n",
      "<class 'torch.Tensor'> 8.377142906188965\n",
      "<class 'torch.Tensor'> 8.322915077209473\n",
      "<class 'torch.Tensor'> 8.563617706298828\n",
      "<class 'torch.Tensor'> 11.4178466796875\n",
      "<class 'torch.Tensor'> 8.908555030822754\n",
      "<class 'torch.Tensor'> 13.528069496154785\n",
      "<class 'torch.Tensor'> 9.650193214416504\n",
      "<class 'torch.Tensor'> 9.652081489562988\n",
      "<class 'torch.Tensor'> 7.638773441314697\n",
      "<class 'torch.Tensor'> 8.612881660461426\n",
      "<class 'torch.Tensor'> 8.646761894226074\n",
      "<class 'torch.Tensor'> 8.075117111206055\n",
      "<class 'torch.Tensor'> 8.337579727172852\n",
      "<class 'torch.Tensor'> 7.780153274536133\n",
      "<class 'torch.Tensor'> 7.757970809936523\n",
      "<class 'torch.Tensor'> 11.598034858703613\n",
      "<class 'torch.Tensor'> 12.809290885925293\n",
      "<class 'torch.Tensor'> 8.90876579284668\n",
      "<class 'torch.Tensor'> 7.843353271484375\n",
      "<class 'torch.Tensor'> 7.848217010498047\n",
      "<class 'torch.Tensor'> 7.736690998077393\n",
      "<class 'torch.Tensor'> 7.526816368103027\n",
      "<class 'torch.Tensor'> 11.250996589660645\n",
      "<class 'torch.Tensor'> 10.302958488464355\n",
      "<class 'torch.Tensor'> 8.606707572937012\n",
      "<class 'torch.Tensor'> 9.271871566772461\n",
      "<class 'torch.Tensor'> 8.589991569519043\n",
      "<class 'torch.Tensor'> 9.4133939743042\n",
      "<class 'torch.Tensor'> 10.720982551574707\n",
      "<class 'torch.Tensor'> 13.98331356048584\n",
      "<class 'torch.Tensor'> 7.976057529449463\n",
      "<class 'torch.Tensor'> 8.074525833129883\n",
      "<class 'torch.Tensor'> 8.05419921875\n",
      "<class 'torch.Tensor'> 7.668112754821777\n",
      "<class 'torch.Tensor'> 11.364853858947754\n",
      "<class 'torch.Tensor'> 7.485616683959961\n",
      "<class 'torch.Tensor'> 7.6718292236328125\n",
      "<class 'torch.Tensor'> 7.631636142730713\n",
      "<class 'torch.Tensor'> 10.474776268005371\n",
      "<class 'torch.Tensor'> 10.150188446044922\n",
      "<class 'torch.Tensor'> 8.218976020812988\n",
      "<class 'torch.Tensor'> 7.721816062927246\n",
      "<class 'torch.Tensor'> 7.761117935180664\n",
      "<class 'torch.Tensor'> 8.311161994934082\n",
      "<class 'torch.Tensor'> 7.6099443435668945\n",
      "<class 'torch.Tensor'> 10.628226280212402\n",
      "<class 'torch.Tensor'> 8.226853370666504\n",
      "<class 'torch.Tensor'> 8.715577125549316\n",
      "<class 'torch.Tensor'> 9.152253150939941\n",
      "<class 'torch.Tensor'> 7.92237663269043\n",
      "<class 'torch.Tensor'> 12.774724960327148\n",
      "<class 'torch.Tensor'> 9.920555114746094\n",
      "<class 'torch.Tensor'> 8.1018648147583\n",
      "<class 'torch.Tensor'> 8.04089069366455\n",
      "<class 'torch.Tensor'> 7.585636138916016\n",
      "<class 'torch.Tensor'> 14.098325729370117\n",
      "<class 'torch.Tensor'> 7.723928928375244\n",
      "<class 'torch.Tensor'> 9.716358184814453\n",
      "<class 'torch.Tensor'> 7.61795711517334\n",
      "<class 'torch.Tensor'> 8.579314231872559\n",
      "<class 'torch.Tensor'> 7.486194610595703\n",
      "<class 'torch.Tensor'> 9.462332725524902\n",
      "<class 'torch.Tensor'> 10.233232498168945\n",
      "<class 'torch.Tensor'> 7.515420913696289\n"
     ]
    }
   ],
   "source": [
    "pred = map(mlp.forward, X_test)\n",
    "for res in pred:\n",
    "    print(type(res), res.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84699eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
